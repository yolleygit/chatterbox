#!/usr/bin/env python3
"""
è¯­éŸ³å…‹éš†è¯¦ç»†æ•™ç¨‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨Chatterbox TTSè¿›è¡Œè¯­éŸ³å…‹éš†
"""

import torch
import torchaudio as ta
from chatterbox.tts import ChatterboxTTS
import os
from pathlib import Path
import time
import librosa
import numpy as np

def apply_torch_load_patch():
    """åº”ç”¨torch.loadè¡¥ä¸ï¼Œå¤„ç†è®¾å¤‡æ˜ å°„é—®é¢˜"""
    original_load = torch.load
    
    def patched_load(f, map_location=None, **kwargs):
        if map_location is None and not torch.cuda.is_available():
            map_location = torch.device('cpu')
        try:
            return original_load(f, map_location=map_location, **kwargs)
        except RuntimeError as e:
            if "CUDA" in str(e):
                print(f"âš ï¸  è‡ªåŠ¨ä¿®å¤CUDAè®¾å¤‡æ˜ å°„é”™è¯¯")
                return original_load(f, map_location=torch.device('cpu'), **kwargs)
            raise e
    
    torch.load = patched_load

def detect_device():
    """æ™ºèƒ½è®¾å¤‡æ£€æµ‹"""
    if torch.backends.mps.is_available():
        try:
            test_tensor = torch.tensor([1.0], device='mps')
            _ = test_tensor + 1
            return 'mps'
        except:
            return 'cpu'
    elif torch.cuda.is_available():
        return 'cuda'
    else:
        return 'cpu'

def analyze_audio_file(audio_path):
    """åˆ†æéŸ³é¢‘æ–‡ä»¶è´¨é‡"""
    try:
        audio, sr = librosa.load(audio_path, sr=None)
        duration = len(audio) / sr
        
        print(f"ğŸ“Š éŸ³é¢‘åˆ†æç»“æœ:")
        print(f"   ğŸ“ æ–‡ä»¶: {audio_path}")
        print(f"   â±ï¸  æ—¶é•¿: {duration:.2f}ç§’")
        print(f"   ğŸ“ˆ é‡‡æ ·ç‡: {sr}Hz")
        print(f"   ğŸ”Š æœ€å¤§éŸ³é‡: {np.max(np.abs(audio)):.3f}")
        print(f"   ğŸ’¾ æ–‡ä»¶å¤§å°: {os.path.getsize(audio_path)/1024:.1f}KB")
        
        # è´¨é‡å»ºè®®
        if duration < 3:
            print(f"   âš ï¸  æ—¶é•¿åçŸ­ï¼Œå»ºè®®3-10ç§’")
        elif duration > 20:
            print(f"   âš ï¸  æ—¶é•¿åé•¿ï¼Œå»ºè®®3-10ç§’")
        else:
            print(f"   âœ… æ—¶é•¿åˆé€‚")
            
        if sr < 16000:
            print(f"   âš ï¸  é‡‡æ ·ç‡åä½ï¼Œå»ºè®®16kHz+")
        else:
            print(f"   âœ… é‡‡æ ·ç‡åˆé€‚")
            
        return True
    except Exception as e:
        print(f"   âŒ åˆ†æå¤±è´¥: {e}")
        return False

def find_voice_samples():
    """æŸ¥æ‰¾å¯ç”¨çš„è¯­éŸ³æ ·æœ¬æ–‡ä»¶"""
    voice_extensions = ['.wav', '.mp3', '.flac', '.m4a']
    voice_samples = []
    
    # æ£€æŸ¥å¸¸è§ä½ç½®
    search_paths = [
        ".",  # å½“å‰ç›®å½•
        "voice_samples/",
        "audio_samples/", 
        "samples/",
        "voices/"
    ]
    
    for search_path in search_paths:
        if os.path.exists(search_path):
            for file in os.listdir(search_path):
                if any(file.lower().endswith(ext) for ext in voice_extensions):
                    full_path = os.path.join(search_path, file)
                    voice_samples.append(full_path)
    
    return voice_samples

def voice_cloning_demo():
    """è¯­éŸ³å…‹éš†æ¼”ç¤º"""
    print("ğŸ­ è¯­éŸ³å…‹éš†è¯¦ç»†æ•™ç¨‹")
    print("=" * 60)
    
    # åº”ç”¨è¡¥ä¸å’Œç¯å¢ƒè®¾ç½®
    apply_torch_load_patch()
    device = detect_device()
    print(f"ğŸ¯ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("output/voice_cloning")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ç¯å¢ƒä¼˜åŒ–
    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
    if torch.get_num_threads() > 4:
        torch.set_num_threads(4)
    
    print("\nâ³ æ­£åœ¨åŠ è½½Chatterbox TTSæ¨¡å‹...")
    start_time = time.time()
    
    try:
        model = ChatterboxTTS.from_pretrained(device="cpu")
        load_time = time.time() - start_time
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (è€—æ—¶: {load_time:.2f}ç§’)")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    print("\n" + "="*60)
    print("ğŸ“š è¯­éŸ³å…‹éš†æ•™ç¨‹")
    print("="*60)
    
    print("\n1ï¸âƒ£ ä»€ä¹ˆæ˜¯è¯­éŸ³å…‹éš†ï¼Ÿ")
    print("è¯­éŸ³å…‹éš†æ˜¯é€šè¿‡æä¾›ä¸€ä¸ªå‚è€ƒéŸ³é¢‘æ–‡ä»¶ï¼Œè®©AIæ¨¡å‹å­¦ä¹ å…¶å£°éŸ³ç‰¹å¾ï¼Œ")
    print("ç„¶åç”¨è¿™ä¸ªå£°éŸ³ç‰¹å¾æ¥åˆæˆæ–°çš„æ–‡æœ¬å†…å®¹ã€‚")
    
    print("\n2ï¸âƒ£ è¯­éŸ³å…‹éš†çš„å·¥ä½œåŸç†ï¼š")
    print("å‚è€ƒéŸ³é¢‘ â†’ å£°éŸ³ç‰¹å¾æå– â†’ ç‰¹å¾èåˆ â†’ æ–°æ–‡æœ¬åˆæˆ â†’ ç›®æ ‡å£°éŸ³è¾“å‡º")
    
    print("\n3ï¸âƒ£ éŸ³é¢‘æ–‡ä»¶è¦æ±‚ï¼š")
    print("âœ… æ ¼å¼: WAV, MP3, FLACç­‰")
    print("âœ… æ—¶é•¿: 3-10ç§’ï¼ˆæ¨èï¼‰")
    print("âœ… è´¨é‡: æ¸…æ™°ã€æ— å™ªéŸ³")
    print("âœ… å†…å®¹: è‡ªç„¶è¯´è¯ï¼Œä¸è¦æœ—è¯»")
    print("âœ… é‡‡æ ·ç‡: 16kHzæˆ–æ›´é«˜")
    
    print("\n4ï¸âƒ£ æŸ¥æ‰¾å¯ç”¨çš„éŸ³é¢‘æ–‡ä»¶...")
    voice_samples = find_voice_samples()
    
    if voice_samples:
        print(f"âœ… æ‰¾åˆ° {len(voice_samples)} ä¸ªéŸ³é¢‘æ–‡ä»¶:")
        for i, sample in enumerate(voice_samples[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"   {i}. {sample}")
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„éŸ³é¢‘æ–‡ä»¶è¿›è¡Œæ¼”ç¤º
        reference_audio = voice_samples[0]
        print(f"\nğŸ¯ é€‰æ‹©éŸ³é¢‘æ–‡ä»¶è¿›è¡Œæ¼”ç¤º: {reference_audio}")
        
        # åˆ†æéŸ³é¢‘æ–‡ä»¶
        if analyze_audio_file(reference_audio):
            print("\n5ï¸âƒ£ å¼€å§‹è¯­éŸ³å…‹éš†æ¼”ç¤º...")
            demo_voice_cloning(model, reference_audio, output_dir)
        else:
            print("âŒ éŸ³é¢‘æ–‡ä»¶åˆ†æå¤±è´¥ï¼Œæ— æ³•è¿›è¡Œæ¼”ç¤º")
    else:
        print("âŒ æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
        print("\nğŸ’¡ è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤å‡†å¤‡éŸ³é¢‘æ–‡ä»¶ï¼š")
        create_sample_instructions()

def demo_voice_cloning(model, reference_audio, output_dir):
    """æ¼”ç¤ºè¯­éŸ³å…‹éš†è¿‡ç¨‹"""
    print(f"\nğŸ­ ä½¿ç”¨ {reference_audio} è¿›è¡Œè¯­éŸ³å…‹éš†...")
    
    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "Hello, this is a voice cloning demonstration.",
        "The weather is beautiful today, perfect for a walk.",
        "Artificial intelligence technology is advancing rapidly.",
        "Thank you for trying out the voice cloning feature."
    ]
    
    print(f"ğŸ“ å°†åˆæˆ {len(test_texts)} æ®µæ–‡æœ¬")
    
    total_start = time.time()
    
    for i, text in enumerate(test_texts, 1):
        print(f"\nğŸ“ ç¬¬{i}æ®µ: {text}")
        
        try:
            start_time = time.time()
            
            # å…³é”®ï¼šä½¿ç”¨å‚è€ƒéŸ³é¢‘è¿›è¡Œè¯­éŸ³å…‹éš†
            wav_tensor = model.generate(
                text=text,
                audio_prompt_path=reference_audio,  # å‚è€ƒéŸ³é¢‘æ–‡ä»¶
                exaggeration=0.6,  # æƒ…æ„Ÿè¡¨è¾¾åº¦
                cfg_weight=0.7,    # ä¸€è‡´æ€§æƒé‡ï¼Œè¶Šé«˜è¶Šåƒå‚è€ƒéŸ³é¢‘
                temperature=0.8    # éšæœºæ€§ï¼Œå½±å“å£°éŸ³å˜åŒ–
            )
            
            # ä¿å­˜éŸ³é¢‘
            output_path = output_dir / f"cloned_voice_{i}.wav"
            ta.save(output_path, wav_tensor, model.sr)
            
            generation_time = time.time() - start_time
            audio_duration = wav_tensor.shape[1] / model.sr
            rtf = generation_time / audio_duration
            
            print(f"  âœ… ç”Ÿæˆå®Œæˆ")
            print(f"  ğŸ“ ä¿å­˜è·¯å¾„: {output_path}")
            print(f"  â±ï¸  ç”Ÿæˆè€—æ—¶: {generation_time:.2f}ç§’")
            print(f"  ğŸ¼ éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f}ç§’")
            print(f"  ğŸ“Š å®æ—¶å› å­: {rtf:.2f}x")
            
        except Exception as e:
            print(f"  âŒ ç”Ÿæˆå¤±è´¥: {e}")
            continue
    
    total_time = time.time() - total_start
    print(f"\nğŸ‰ è¯­éŸ³å…‹éš†æ¼”ç¤ºå®Œæˆï¼")
    print(f"ğŸ“‚ æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {output_dir}")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f}ç§’")
    
    # å‚æ•°è°ƒä¼˜å»ºè®®
    print_parameter_tuning_tips()

def create_sample_instructions():
    """åˆ›å»ºéŸ³é¢‘æ ·æœ¬å‡†å¤‡è¯´æ˜"""
    print("\nğŸ“– éŸ³é¢‘æ ·æœ¬å‡†å¤‡æŒ‡å—:")
    print("="*40)
    
    print("\nğŸ™ï¸ å½•åˆ¶æ–¹æ³•:")
    print("1. ä½¿ç”¨Macå†…ç½®å½•éŸ³åº”ç”¨")
    print("2. æˆ–ä½¿ç”¨QuickTime Player â†’ æ–‡ä»¶ â†’ æ–°å»ºéŸ³é¢‘å½•åˆ¶")
    print("3. å½•åˆ¶3-10ç§’è‡ªç„¶è¯´è¯")
    print("4. ä¿å­˜ä¸ºvoice_sample.wav")
    
    print("\nğŸ’¾ ä¸‹è½½æ–¹æ³•:")
    print("1. ä»è¯­éŸ³æ•°æ®é›†ä¸‹è½½ï¼ˆå¦‚CommonVoiceï¼‰")
    print("2. ä»æ’­å®¢æˆ–è§†é¢‘ä¸­æå–éŸ³é¢‘ç‰‡æ®µ")
    print("3. ä½¿ç”¨å…¶ä»–TTSå·¥å…·ç”Ÿæˆæ ·æœ¬")
    
    print("\nğŸ“ æ–‡ä»¶æ”¾ç½®:")
    print("å°†éŸ³é¢‘æ–‡ä»¶æ”¾åœ¨ä»¥ä¸‹ä»»ä¸€ä½ç½®ï¼š")
    print("- é¡¹ç›®æ ¹ç›®å½•")
    print("- voice_samples/ ç›®å½•")
    print("- audio_samples/ ç›®å½•")
    
    print("\nğŸ”§ éŸ³é¢‘å¤„ç†å·¥å…·æ¨è:")
    print("- Audacity (å…è´¹ï¼Œè·¨å¹³å°)")
    print("- FFmpeg (å‘½ä»¤è¡Œå·¥å…·)")
    print("- Macå†…ç½®éŸ³é¢‘å¤„ç†")

def print_parameter_tuning_tips():
    """æ‰“å°å‚æ•°è°ƒä¼˜å»ºè®®"""
    print("\nğŸ›ï¸ å‚æ•°è°ƒä¼˜æŒ‡å—:")
    print("="*40)
    
    print("\nğŸ“Š cfg_weight (ä¸€è‡´æ€§æƒé‡) 0.1-1.0:")
    print("  â€¢ 0.3-0.5: æ›´æœ‰åˆ›æ„ï¼Œå£°éŸ³å˜åŒ–è¾ƒå¤§")
    print("  â€¢ 0.6-0.8: å¹³è¡¡ï¼Œæ¨èå€¼")
    print("  â€¢ 0.8-1.0: æ›´åƒå‚è€ƒéŸ³é¢‘ï¼Œæ›´ä¸€è‡´")
    
    print("\nğŸ­ exaggeration (æƒ…æ„Ÿè¡¨è¾¾) 0.1-2.0:")
    print("  â€¢ 0.1-0.4: å¹³æ·¡ï¼Œé€‚åˆæ­£å¼åœºåˆ")
    print("  â€¢ 0.5-0.8: è‡ªç„¶ï¼Œæ¨èå€¼")
    print("  â€¢ 0.9-2.0: å¤¸å¼ ï¼Œé€‚åˆæˆå‰§è¡¨æ¼”")
    
    print("\nğŸ² temperature (éšæœºæ€§) 0.1-2.0:")
    print("  â€¢ 0.1-0.5: æ›´ç¨³å®šï¼Œé‡å¤æ€§å¥½")
    print("  â€¢ 0.6-1.0: å¹³è¡¡ï¼Œæ¨èå€¼")
    print("  â€¢ 1.1-2.0: æ›´å¤šæ ·ï¼Œæ¯æ¬¡ä¸åŒ")
    
    print("\nğŸ’¡ æ¨èç»„åˆ:")
    print("  â€¢ é«˜è´¨é‡å…‹éš†: cfg_weight=0.8, exaggeration=0.6, temperature=0.7")
    print("  â€¢ åˆ›æ„è¡¨è¾¾: cfg_weight=0.5, exaggeration=1.0, temperature=1.2")
    print("  â€¢ ç¨³å®šè¾“å‡º: cfg_weight=0.9, exaggeration=0.4, temperature=0.5")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨è¯­éŸ³å…‹éš†æ•™ç¨‹...")
    voice_cloning_demo()
    
    print("\n" + "="*60)
    print("ğŸ“š è¡¥å……è¯´æ˜")
    print("="*60)
    
    print("\nâœ¨ è¯­éŸ³å…‹éš†çš„åº”ç”¨åœºæ™¯:")
    print("â€¢ ğŸ“– æœ‰å£°ä¹¦åˆ¶ä½œ")
    print("â€¢ ğŸ¬ è§†é¢‘é…éŸ³")
    print("â€¢ ğŸ¤– ä¸ªæ€§åŒ–è¯­éŸ³åŠ©æ‰‹")
    print("â€¢ ğŸµ éŸ³ä¹å’Œæ’­å®¢åˆ¶ä½œ")
    print("â€¢ ğŸŒ å¤šè¯­è¨€å†…å®¹æœ¬åœ°åŒ–")
    
    print("\nâš–ï¸ ä½¿ç”¨æ³¨æ„äº‹é¡¹:")
    print("â€¢ ğŸ”’ ä»…ç”¨äºåˆæ³•å’Œé“å¾·ç›®çš„")
    print("â€¢ ğŸ‘¤ è·å¾—å£°éŸ³æ‰€æœ‰è€…åŒæ„")
    print("â€¢ ğŸš« ä¸ç”¨äºæ¬ºè¯ˆæˆ–è¯¯å¯¼")
    print("â€¢ ğŸ“œ éµå®ˆå½“åœ°æ³•å¾‹æ³•è§„")
    
    print("\nğŸ”— ç›¸å…³æ–‡ä»¶:")
    print("â€¢ examples/advanced/voice_cloning_example.py - åŸºç¡€è¯­éŸ³å…‹éš†")
    print("â€¢ examples/basic/chinese_tts_example.py - ä¸­æ–‡è¯­éŸ³å…‹éš†")
    print("â€¢ ä¸­æ–‡è¯­éŸ³åˆæˆè§£å†³æ–¹æ¡ˆ.md - è¯¦ç»†è§£å†³æ–¹æ¡ˆ")

if __name__ == "__main__":
    main() 