#!/usr/bin/env python3
"""
Chatterbox TTS åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹ (ç¦»çº¿ç‰ˆæœ¬)
æ¼”ç¤ºæœ€ç®€å•çš„æ–‡æœ¬è½¬è¯­éŸ³åŠŸèƒ½ï¼Œä½¿ç”¨æœ¬åœ°ç¼“å­˜é¿å…ç½‘ç»œé—®é¢˜
"""

import torch
import torchaudio as ta
from chatterbox.tts import ChatterboxTTS
import os
from pathlib import Path

def find_local_model_path():
    """æŸ¥æ‰¾æœ¬åœ°ç¼“å­˜çš„æ¨¡å‹è·¯å¾„"""
    # Hugging Faceç¼“å­˜è·¯å¾„
    hf_cache_dir = Path.home() / ".cache" / "huggingface" / "hub"
    
    # æŸ¥æ‰¾chatterboxç›¸å…³çš„ç›®å½•
    for model_dir in hf_cache_dir.glob("models--ResembleAI--chatterbox*"):
        snapshots_dir = model_dir / "snapshots"
        if snapshots_dir.exists():
            # è·å–æœ€æ–°çš„å¿«ç…§
            snapshots = list(snapshots_dir.iterdir())
            if snapshots:
                latest_snapshot = max(snapshots, key=lambda x: x.stat().st_mtime)
                return latest_snapshot
    
    return None

def apply_torch_load_patch():
    """åº”ç”¨torch.loadè¡¥ä¸ï¼Œå¤„ç†è®¾å¤‡æ˜ å°„é—®é¢˜"""
    original_load = torch.load
    
    def patched_load(f, map_location=None, **kwargs):
        if map_location is None and not torch.cuda.is_available():
            map_location = torch.device('cpu')
        try:
            return original_load(f, map_location=map_location, **kwargs)
        except RuntimeError as e:
            if "CUDA" in str(e):
                print(f"âš ï¸  è‡ªåŠ¨ä¿®å¤CUDAè®¾å¤‡æ˜ å°„é”™è¯¯")
                return original_load(f, map_location=torch.device('cpu'), **kwargs)
            raise e
    
    torch.load = patched_load

def basic_tts_demo_offline():
    """åŸºæœ¬TTSæ¼”ç¤ºï¼ˆç¦»çº¿ç‰ˆæœ¬ï¼‰"""
    print("ğŸ¤ åˆå§‹åŒ–Chatterbox TTSæ¨¡å‹ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰...")
    
    # åº”ç”¨è®¾å¤‡æ˜ å°„è¡¥ä¸
    apply_torch_load_patch()
    
    # è‡ªåŠ¨æ£€æµ‹æœ€ä½³è®¾å¤‡
    if torch.cuda.is_available():
        device = "cuda"
        print("ğŸš€ ä½¿ç”¨CUDAåŠ é€Ÿ")
    elif torch.backends.mps.is_available():
        device = "mps"
        print("ğŸ ä½¿ç”¨Apple MetalåŠ é€Ÿ")
    else:
        device = "cpu"
        print("ğŸ’» ä½¿ç”¨CPUæ¨ç†")

    # é¦–å…ˆå°è¯•æŸ¥æ‰¾æœ¬åœ°ç¼“å­˜
    local_path = find_local_model_path()
    
    try:
        if local_path and local_path.exists():
            print(f"ğŸ“ ä½¿ç”¨æœ¬åœ°ç¼“å­˜: {local_path}")
            # ä½¿ç”¨æœ¬åœ°è·¯å¾„åŠ è½½
            model = ChatterboxTTS.from_local(local_path, device="cpu")
        else:
            print("â³ æœ¬åœ°ç¼“å­˜æœªæ‰¾åˆ°ï¼Œå°è¯•åœ¨çº¿ä¸‹è½½...")
            model = ChatterboxTTS.from_pretrained(device="cpu")
        
        # å¦‚æœç›®æ ‡è®¾å¤‡æ˜¯MPSï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
        if device == "mps":
            print("ğŸ”„ å°†æ¨¡å‹è½¬ç§»åˆ°MPSè®¾å¤‡...")
            model = model.to(device)
            # æ¸…ç†MPSç¼“å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                torch.mps.empty_cache()
            except AttributeError:
                pass
        elif device != "cpu":
            print(f"ğŸ”„ å°†æ¨¡å‹è½¬ç§»åˆ°{device}è®¾å¤‡...")
            model = model.to(device)
            
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
        
    except Exception as e:
        print(f"âš ï¸  æ¨¡å‹åŠ è½½é‡åˆ°é—®é¢˜: {e}")
        print("ğŸ”„ å›é€€åˆ°CPUæ¨¡å¼...")
        try:
            model = ChatterboxTTS.from_pretrained(device="cpu")
            device = "cpu"
            print("âœ… CPUæ¨¡å¼åŠ è½½æˆåŠŸ")
        except Exception as fallback_error:
            print(f"âŒ CPUæ¨¡å¼ä¹Ÿå¤±è´¥äº†: {fallback_error}")
            print("ğŸ’¡ å»ºè®®:")
            print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
            print("   2. å°è¯•é‡å¯Pythonä¼šè¯")
            print("   3. ç¡®è®¤condaç¯å¢ƒæ­£ç¡®æ¿€æ´»")
            return

    # è¦åˆæˆçš„æ–‡æœ¬
    text = "ä½ å¥½ï¼Œæˆ‘æ˜¯Chatterboxï¼Œä¸€ä¸ªå¼€æºçš„è¯­éŸ³åˆæˆç³»ç»Ÿã€‚ä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼"
    
    print(f"ğŸ“ åˆæˆæ–‡æœ¬: {text}")
    print("â³ æ­£åœ¨ç”Ÿæˆè¯­éŸ³...")
    
    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path("output/audio")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆè¯­éŸ³
        with torch.no_grad():  # å‡å°‘å†…å­˜ä½¿ç”¨
            wav = model.generate(text)
        
        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        output_path = output_dir / "basic_output_offline.wav"
        ta.save(output_path, wav, model.sr)
        
        print(f"ğŸµ è¯­éŸ³å·²ä¿å­˜åˆ°: {output_path}")
        print(f"ğŸ“Š é‡‡æ ·ç‡: {model.sr}Hz")
        print(f"â±ï¸  æ—¶é•¿: {wav.shape[1] / model.sr:.2f}ç§’")
        print(f"ğŸ¯ ä½¿ç”¨è®¾å¤‡: {device}")
        
        # æ¸…ç†å†…å­˜
        if device == "mps":
            try:
                torch.mps.empty_cache()
            except AttributeError:
                pass
                
    except Exception as e:
        print(f"âŒ è¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")
        print("ğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("   1. é‡å¯Pythonä¼šè¯")
        print("   2. ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†…å­˜")
        print("   3. å°è¯•ä½¿ç”¨CPUæ¨¡å¼")

if __name__ == "__main__":
    basic_tts_demo_offline() 