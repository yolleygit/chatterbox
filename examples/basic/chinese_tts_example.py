#!/usr/bin/env python3
"""
ä¸­æ–‡è¯­éŸ³åˆæˆç¤ºä¾‹
è§£å†³ä¸­æ–‡æ–‡æœ¬è¾“å‡ºè‹±æ–‡è¯­éŸ³çš„é—®é¢˜
"""

import torch
import torchaudio as ta
from chatterbox.tts import ChatterboxTTS
import os
from pathlib import Path
import time

def detect_device():
    """æ™ºèƒ½è®¾å¤‡æ£€æµ‹"""
    if torch.backends.mps.is_available():
        try:
            # æµ‹è¯•MPSè®¾å¤‡æ˜¯å¦æ­£å¸¸å·¥ä½œ
            test_tensor = torch.tensor([1.0], device='mps')
            _ = test_tensor + 1
            return 'mps'
        except:
            return 'cpu'
    elif torch.cuda.is_available():
        return 'cuda'
    else:
        return 'cpu'

def create_chinese_voice_prompt():
    """
    åˆ›å»ºä¸­æ–‡è¯­éŸ³æç¤º
    æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ä¸€ä¸ªä¸­æ–‡è¯­éŸ³æ–‡ä»¶ä½œä¸ºå‚è€ƒ
    å¦‚æœæ²¡æœ‰ä¸­æ–‡è¯­éŸ³æ–‡ä»¶ï¼ŒChatterboxä¼šä½¿ç”¨å†…ç½®çš„è‹±æ–‡è¯­éŸ³æ¨¡æ¿
    """
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸­æ–‡è¯­éŸ³æ–‡ä»¶
    chinese_voice_files = [
        "chinese_voice.wav",
        "ä¸­æ–‡è¯­éŸ³.wav", 
        "output/chinese_reference.wav"
    ]
    
    for voice_file in chinese_voice_files:
        if os.path.exists(voice_file):
            print(f"âœ… æ‰¾åˆ°ä¸­æ–‡è¯­éŸ³æ–‡ä»¶: {voice_file}")
            return voice_file
    
    print("âš ï¸  æœªæ‰¾åˆ°ä¸­æ–‡è¯­éŸ³æ–‡ä»¶ï¼Œå°†ä½¿ç”¨å†…ç½®è¯­éŸ³æ¨¡æ¿")
    print("ğŸ’¡ å»ºè®®ï¼š")
    print("   1. å½•åˆ¶ä¸€æ®µ3-10ç§’çš„ä¸­æ–‡è¯­éŸ³ï¼Œä¿å­˜ä¸º 'chinese_voice.wav'")
    print("   2. æˆ–ä»ç½‘ä¸Šä¸‹è½½ä¸­æ–‡è¯­éŸ³æ ·æœ¬")
    print("   3. æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹")
    return None

def apply_torch_load_patch():
    """åº”ç”¨torch.loadè¡¥ä¸ï¼Œå¤„ç†è®¾å¤‡æ˜ å°„é—®é¢˜"""
    original_load = torch.load
    
    def patched_load(f, map_location=None, **kwargs):
        if map_location is None and not torch.cuda.is_available():
            map_location = torch.device('cpu')
        try:
            return original_load(f, map_location=map_location, **kwargs)
        except RuntimeError as e:
            if "CUDA" in str(e):
                print(f"âš ï¸  è‡ªåŠ¨ä¿®å¤CUDAè®¾å¤‡æ˜ å°„é”™è¯¯")
                return original_load(f, map_location=torch.device('cpu'), **kwargs)
            raise e
    
    torch.load = patched_load

def main():
    print("ğŸ¤ ä¸­æ–‡è¯­éŸ³åˆæˆç¤ºä¾‹")
    print("=" * 50)
    
    # åº”ç”¨è®¾å¤‡æ˜ å°„è¡¥ä¸
    apply_torch_load_patch()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("output/audio")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è®¾å¤‡æ£€æµ‹
    device = detect_device()
    print(f"ğŸ¯ ä½¿ç”¨è®¾å¤‡: {device}")
    if device == "mps":
        print("ğŸ å¯ç”¨Apple MetalåŠ é€Ÿ")
    
    # ç¯å¢ƒä¼˜åŒ–
    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
    if torch.get_num_threads() > 4:
        torch.set_num_threads(4)
    
    print("\nâ³ æ­£åœ¨åŠ è½½Chatterbox TTSæ¨¡å‹...")
    start_time = time.time()
    
    try:
        # ä¸ºMacè®¾å¤‡ä¼˜åŒ–åŠ è½½
        if device == "mps":
            model = ChatterboxTTS.from_pretrained(device="cpu")
            # æ³¨æ„ï¼šChatterbox TTSæ¨¡å‹æœ¬èº«ä¸æ”¯æŒ.to()æ–¹æ³•
            print("âš ï¸  æ¨¡å‹å·²åŠ è½½åˆ°CPUï¼ˆChatterbox TTSé™åˆ¶ï¼‰")
            device_actual = "cpu"
        else:
            model = ChatterboxTTS.from_pretrained(device=device)
            device_actual = device
            
        load_time = time.time() - start_time
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (è€—æ—¶: {load_time:.2f}ç§’)")
        
    except RuntimeError as e:
        if "CUDA" in str(e):
            print("âš ï¸  æ£€æµ‹åˆ°CUDAé”™è¯¯ï¼Œå›é€€åˆ°CPUæ¨¡å¼...")
            model = ChatterboxTTS.from_pretrained(device="cpu")
            device_actual = "cpu"
            print("âœ… CPUæ¨¡å¼åŠ è½½æˆåŠŸ")
        else:
            raise e
    
    # æ£€æŸ¥ä¸­æ–‡è¯­éŸ³æç¤º
    chinese_voice_prompt = create_chinese_voice_prompt()
    
    # ä¸­æ–‡æµ‹è¯•æ–‡æœ¬
    chinese_texts = [
        "ä½ å¥½ï¼Œè¿™æ˜¯ä¸­æ–‡è¯­éŸ³åˆæˆæµ‹è¯•ã€‚",
        "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºå»èµ°èµ°ã€‚",
        "äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•éå¸¸è¿…é€Ÿã€‚"
    ]
    
    print(f"\nğŸµ å¼€å§‹ä¸­æ–‡è¯­éŸ³åˆæˆ...")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    for i, text in enumerate(chinese_texts, 1):
        print(f"\nğŸ“ ç¬¬{i}æ®µ: {text}")
        
        try:
            start_time = time.time()
            
            # å…³é”®ï¼šä½¿ç”¨ä¸­æ–‡è¯­éŸ³æç¤º
            if chinese_voice_prompt:
                wav_tensor = model.generate(
                    text=text,
                    audio_prompt_path=chinese_voice_prompt,  # ä¸­æ–‡è¯­éŸ³å‚è€ƒ
                    exaggeration=0.8,  # ç¨å¾®å¢åŠ æƒ…æ„Ÿè¡¨è¾¾
                    cfg_weight=0.6,    # å¢åŠ ä¸€è‡´æ€§
                    temperature=0.7    # é€‚ä¸­çš„éšæœºæ€§
                )
                print("  ğŸ¯ ä½¿ç”¨ä¸­æ–‡è¯­éŸ³æç¤º")
            else:
                # æ²¡æœ‰ä¸­æ–‡è¯­éŸ³æç¤ºæ—¶çš„è®¾ç½®
                wav_tensor = model.generate(
                    text=text,
                    exaggeration=0.5,  # æ ‡å‡†æƒ…æ„Ÿè¡¨è¾¾
                    cfg_weight=0.7,    # é«˜ä¸€è‡´æ€§ï¼Œå‡å°‘è‹±æ–‡å€¾å‘
                    temperature=0.6    # è¾ƒä½éšæœºæ€§
                )
                print("  âš ï¸  ä½¿ç”¨å†…ç½®è¯­éŸ³æ¨¡æ¿ï¼ˆå¯èƒ½è¾“å‡ºè‹±æ–‡ï¼‰")
            
            # ä¿å­˜éŸ³é¢‘
            output_path = output_dir / f"chinese_output_{i}.wav"
            ta.save(output_path, wav_tensor, model.sr)
            
            generation_time = time.time() - start_time
            audio_duration = wav_tensor.shape[1] / model.sr
            rtf = generation_time / audio_duration
            
            print(f"  âœ… ç”Ÿæˆå®Œæˆ")
            print(f"  ğŸ“ ä¿å­˜è·¯å¾„: {output_path}")
            print(f"  â±ï¸  ç”Ÿæˆè€—æ—¶: {generation_time:.2f}ç§’")
            print(f"  ğŸ¼ éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f}ç§’")
            print(f"  ğŸ“Š å®æ—¶å› å­: {rtf:.2f}x")
            
        except Exception as e:
            print(f"  âŒ ç”Ÿæˆå¤±è´¥: {e}")
            continue
    
    print(f"\nğŸ‰ ä¸­æ–‡è¯­éŸ³åˆæˆå®Œæˆï¼")
    print(f"ğŸ“‚ æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {output_dir}")
    
    # é‡è¦æç¤º
    print(f"\nğŸ’¡ é‡è¦è¯´æ˜:")
    print("1. ğŸ¯ Chatterbox TTSä¸»è¦ä¸ºè‹±æ–‡ä¼˜åŒ–")
    print("2. ğŸ—£ï¸  è¦è·å¾—çœŸæ­£çš„ä¸­æ–‡è¯­éŸ³ï¼Œéœ€è¦ä¸­æ–‡è¯­éŸ³æ–‡ä»¶ä½œä¸ºå‚è€ƒ")
    print("3. ğŸ“ è¯·å½•åˆ¶æˆ–ä¸‹è½½ä¸­æ–‡è¯­éŸ³æ ·æœ¬ï¼Œå‘½åä¸º 'chinese_voice.wav'")
    print("4. ğŸ”„ ä½¿ç”¨ä¸­æ–‡è¯­éŸ³å‚è€ƒå¯ä»¥æ˜¾è‘—æ”¹å–„ä¸­æ–‡åˆæˆæ•ˆæœ")
    
    if not chinese_voice_prompt:
        print(f"\nâš ï¸  å½“å‰è¾“å‡ºå¯èƒ½ä»æ˜¯è‹±æ–‡è¯­éŸ³ï¼Œå› ä¸º:")
        print("   - æ¨¡å‹ä½¿ç”¨è‹±æ–‡åˆ†è¯å™¨å¤„ç†ä¸­æ–‡æ–‡æœ¬")
        print("   - æ²¡æœ‰ä¸­æ–‡è¯­éŸ³å‚è€ƒæ¥å¼•å¯¼å‘éŸ³")
        print("   - éœ€è¦ä¸­æ–‡voice promptæ¥'æ•™'æ¨¡å‹è¯´ä¸­æ–‡")

if __name__ == "__main__":
    main() 