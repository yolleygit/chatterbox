#!/usr/bin/env python3
"""
è¯­éŸ³å…‹éš†å¿«é€Ÿå…¥é—¨
ç®€å•æ˜“ç”¨çš„è¯­éŸ³å…‹éš†ç¤ºä¾‹
"""

import torch
import torchaudio as ta
from chatterbox.tts import ChatterboxTTS
import os
from pathlib import Path

def apply_torch_load_patch():
    """åº”ç”¨torch.loadè¡¥ä¸"""
    original_load = torch.load
    
    def patched_load(f, map_location=None, **kwargs):
        if map_location is None and not torch.cuda.is_available():
            map_location = torch.device('cpu')
        try:
            return original_load(f, map_location=map_location, **kwargs)
        except RuntimeError as e:
            if "CUDA" in str(e):
                return original_load(f, map_location=torch.device('cpu'), **kwargs)
            raise e
    
    torch.load = patched_load

def quick_voice_clone():
    """å¿«é€Ÿè¯­éŸ³å…‹éš†æ¼”ç¤º"""
    print("ğŸ­ è¯­éŸ³å…‹éš†å¿«é€Ÿå…¥é—¨")
    print("=" * 40)
    
    # åº”ç”¨è¡¥ä¸
    apply_torch_load_patch()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("output/quick_cloning")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("â³ åŠ è½½æ¨¡å‹...")
    model = ChatterboxTTS.from_pretrained(device="cpu")
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å‚è€ƒéŸ³é¢‘æ–‡ä»¶
    reference_files = [
        "voice_sample.wav",
        "reference.wav", 
        "audio_sample.wav",
        "my_voice.wav"
    ]
    
    reference_audio = None
    for file in reference_files:
        if os.path.exists(file):
            reference_audio = file
            break
    
    if reference_audio:
        print(f"ğŸ¯ æ‰¾åˆ°å‚è€ƒéŸ³é¢‘: {reference_audio}")
        
        # è¦å…‹éš†çš„æ–‡æœ¬
        texts = [
            "Hello, this is my cloned voice speaking.",
            "Voice cloning technology is truly amazing.",
            "I hope you enjoy this demonstration."
        ]
        
        print(f"ğŸµ å¼€å§‹è¯­éŸ³å…‹éš†...")
        
        for i, text in enumerate(texts, 1):
            print(f"ğŸ“ æ­£åœ¨å¤„ç†ç¬¬{i}æ®µ: {text}")
            
            # è¯­éŸ³å…‹éš†çš„æ ¸å¿ƒä»£ç 
            wav = model.generate(
                text=text,
                audio_prompt_path=reference_audio,  # å…³é”®ï¼šå‚è€ƒéŸ³é¢‘
                exaggeration=0.7,   # æƒ…æ„Ÿè¡¨è¾¾
                cfg_weight=0.8,     # ç›¸ä¼¼åº¦æ§åˆ¶
                temperature=0.7     # éšæœºæ€§æ§åˆ¶
            )
            
            # ä¿å­˜ç»“æœ
            output_path = output_dir / f"cloned_{i}.wav"
            ta.save(output_path, wav, model.sr)
            print(f"  âœ… ä¿å­˜åˆ°: {output_path}")
        
        print(f"\nğŸ‰ è¯­éŸ³å…‹éš†å®Œæˆï¼æ–‡ä»¶ä¿å­˜åœ¨: {output_dir}")
        
    else:
        print("âŒ æœªæ‰¾åˆ°å‚è€ƒéŸ³é¢‘æ–‡ä»¶")
        print("\nğŸ’¡ è¯·å‡†å¤‡ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶å¹¶å‘½åä¸ºä»¥ä¸‹ä»»ä¸€åç§°ï¼š")
        for file in reference_files:
            print(f"  â€¢ {file}")
        
        print("\nğŸ“ éŸ³é¢‘æ–‡ä»¶è¦æ±‚ï¼š")
        print("  â€¢ æ ¼å¼ï¼šWAV, MP3ç­‰")
        print("  â€¢ æ—¶é•¿ï¼š3-10ç§’")
        print("  â€¢ è´¨é‡ï¼šæ¸…æ™°æ— å™ªéŸ³")
        print("  â€¢ å†…å®¹ï¼šè‡ªç„¶è¯´è¯")
        
        print("\nğŸ™ï¸ å½•åˆ¶æ–¹æ³•ï¼š")
        print("  1. æ‰“å¼€Macçš„è¯­éŸ³å¤‡å¿˜å½•æˆ–QuickTime")
        print("  2. å½•åˆ¶3-10ç§’è‡ªç„¶è¯´è¯")
        print("  3. ä¿å­˜ä¸ºvoice_sample.wav")
        print("  4. æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•")
        print("  5. é‡æ–°è¿è¡Œæ­¤è„šæœ¬")

if __name__ == "__main__":
    quick_voice_clone() 