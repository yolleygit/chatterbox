#!/usr/bin/env python3
"""
ä½¿ç”¨ç°æœ‰éŸ³é¢‘æ–‡ä»¶è¿›è¡Œè¯­éŸ³å…‹éš†æ¼”ç¤º
åˆ©ç”¨é¡¹ç›®ä¸­å·²æœ‰çš„éŸ³é¢‘æ–‡ä»¶ä½œä¸ºå‚è€ƒ
"""

import torch
import torchaudio as ta
from chatterbox.tts import ChatterboxTTS
import os
from pathlib import Path
import glob

def apply_torch_load_patch():
    """åº”ç”¨torch.loadè¡¥ä¸"""
    original_load = torch.load
    
    def patched_load(f, map_location=None, **kwargs):
        if map_location is None and not torch.cuda.is_available():
            map_location = torch.device('cpu')
        try:
            return original_load(f, map_location=map_location, **kwargs)
        except RuntimeError as e:
            if "CUDA" in str(e):
                return original_load(f, map_location=torch.device('cpu'), **kwargs)
            raise e
    
    torch.load = patched_load

def find_existing_audio_files():
    """æŸ¥æ‰¾é¡¹ç›®ä¸­ç°æœ‰çš„éŸ³é¢‘æ–‡ä»¶"""
    audio_patterns = [
        "output/**/*.wav",
        "audio_output/*.wav", 
        "*.wav",
        "**/*.mp3",
        "**/*.flac"
    ]
    
    audio_files = []
    for pattern in audio_patterns:
        files = glob.glob(pattern, recursive=True)
        audio_files.extend(files)
    
    # å»é‡å¹¶è¿‡æ»¤
    unique_files = list(set(audio_files))
    # è¿‡æ»¤æ‰å¯èƒ½çš„è¾“å‡ºæ–‡ä»¶ï¼ˆé¿å…ä½¿ç”¨å…‹éš†çš„ç»“æœä½œä¸ºå‚è€ƒï¼‰
    valid_files = [f for f in unique_files if 'cloned' not in f.lower() and 'voice_cloning' not in f.lower()]
    
    return valid_files

def analyze_audio_quality(audio_path):
    """åˆ†æéŸ³é¢‘æ–‡ä»¶åŸºæœ¬ä¿¡æ¯"""
    try:
        # ä½¿ç”¨torchaudioåŠ è½½éŸ³é¢‘
        waveform, sample_rate = ta.load(audio_path)
        duration = waveform.shape[1] / sample_rate
        channels = waveform.shape[0]
        max_amplitude = torch.max(torch.abs(waveform)).item()
        
        print(f"  ğŸ“Š æ–‡ä»¶åˆ†æ:")
        print(f"     ğŸ“ è·¯å¾„: {audio_path}")
        print(f"     â±ï¸  æ—¶é•¿: {duration:.2f}ç§’")
        print(f"     ğŸ“ˆ é‡‡æ ·ç‡: {sample_rate}Hz")
        print(f"     ğŸ”Š å£°é“æ•°: {channels}")
        print(f"     ğŸ“ˆ æœ€å¤§æŒ¯å¹…: {max_amplitude:.3f}")
        
        # è´¨é‡è¯„ä¼°
        quality_score = 0
        issues = []
        
        if 2 <= duration <= 15:
            quality_score += 2
        elif duration < 2:
            issues.append("æ—¶é•¿è¿‡çŸ­")
        elif duration > 15:
            issues.append("æ—¶é•¿è¿‡é•¿")
        else:
            quality_score += 1
            
        if sample_rate >= 16000:
            quality_score += 2
        else:
            issues.append("é‡‡æ ·ç‡åä½")
            
        if 0.1 <= max_amplitude <= 0.9:
            quality_score += 2
        elif max_amplitude < 0.1:
            issues.append("éŸ³é‡è¿‡å°")
        elif max_amplitude > 0.95:
            issues.append("å¯èƒ½æœ‰å‰Šæ³¢å¤±çœŸ")
        else:
            quality_score += 1
        
        if quality_score >= 5:
            print(f"     âœ… è´¨é‡è¯„åˆ†: {quality_score}/6 (ä¼˜ç§€)")
        elif quality_score >= 3:
            print(f"     ğŸŸ¡ è´¨é‡è¯„åˆ†: {quality_score}/6 (è‰¯å¥½)")
        else:
            print(f"     ğŸ”´ è´¨é‡è¯„åˆ†: {quality_score}/6 (ä¸€èˆ¬)")
            
        if issues:
            print(f"     âš ï¸  æ³¨æ„äº‹é¡¹: {', '.join(issues)}")
            
        return quality_score >= 3, duration
        
    except Exception as e:
        print(f"     âŒ åˆ†æå¤±è´¥: {e}")
        return False, 0

def voice_cloning_demo_with_existing():
    """ä½¿ç”¨ç°æœ‰éŸ³é¢‘æ–‡ä»¶è¿›è¡Œè¯­éŸ³å…‹éš†æ¼”ç¤º"""
    print("ğŸ­ ä½¿ç”¨ç°æœ‰éŸ³é¢‘æ–‡ä»¶è¿›è¡Œè¯­éŸ³å…‹éš†")
    print("=" * 50)
    
    # åº”ç”¨è¡¥ä¸
    apply_torch_load_patch()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("output/voice_cloning")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("ğŸ” æœç´¢ç°æœ‰éŸ³é¢‘æ–‡ä»¶...")
    audio_files = find_existing_audio_files()
    
    if not audio_files:
        print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„éŸ³é¢‘æ–‡ä»¶")
        print("ğŸ’¡ è¯·å…ˆè¿è¡ŒåŸºç¡€TTSç¤ºä¾‹ç”Ÿæˆä¸€äº›éŸ³é¢‘æ–‡ä»¶ï¼Œæˆ–æä¾›è‡ªå·±çš„éŸ³é¢‘æ–‡ä»¶")
        return
    
    print(f"âœ… æ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
    
    # åˆ†æå¹¶é€‰æ‹©æœ€ä½³éŸ³é¢‘æ–‡ä»¶
    best_file = None
    best_score = 0
    
    print("\nğŸ“Š åˆ†æéŸ³é¢‘æ–‡ä»¶è´¨é‡...")
    for i, audio_file in enumerate(audio_files[:5], 1):  # æœ€å¤šåˆ†æ5ä¸ªæ–‡ä»¶
        print(f"\n{i}. åˆ†ææ–‡ä»¶: {audio_file}")
        is_good, duration = analyze_audio_quality(audio_file)
        
        if is_good and duration > best_score:
            best_file = audio_file
            best_score = duration
    
    if not best_file:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é«˜è´¨é‡æ–‡ä»¶ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª
        best_file = audio_files[0]
        print(f"\nâš ï¸  æœªæ‰¾åˆ°é«˜è´¨é‡éŸ³é¢‘ï¼Œå°†ä½¿ç”¨: {best_file}")
    else:
        print(f"\nğŸ¯ é€‰æ‹©æœ€ä½³éŸ³é¢‘æ–‡ä»¶: {best_file}")
    
    print("\nâ³ åŠ è½½Chatterbox TTSæ¨¡å‹...")
    try:
        model = ChatterboxTTS.from_pretrained(device="cpu")
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•æ–‡æœ¬ï¼ˆé’ˆå¯¹è¯­éŸ³å…‹éš†ä¼˜åŒ–çš„å†…å®¹ï¼‰
    test_texts = [
        "This is a voice cloning demonstration using existing audio.",
        "The technology can reproduce voice characteristics remarkably well.",
        "Each generation may sound slightly different due to the random nature.",
        "Voice cloning opens up many creative possibilities."
    ]
    
    print(f"\nğŸµ å¼€å§‹è¯­éŸ³å…‹éš†æ¼”ç¤º...")
    print(f"ğŸ“ å°†ç”Ÿæˆ {len(test_texts)} æ®µè¯­éŸ³")
    
    successful_generations = 0
    
    for i, text in enumerate(test_texts, 1):
        print(f"\nğŸ“ ç¬¬{i}æ®µæ–‡æœ¬: {text}")
        
        try:
            # è¯­éŸ³å…‹éš†å…³é”®ä»£ç 
            wav_tensor = model.generate(
                text=text,
                audio_prompt_path=best_file,  # ä½¿ç”¨é€‰ä¸­çš„éŸ³é¢‘æ–‡ä»¶ä½œä¸ºå‚è€ƒ
                exaggeration=0.7,             # æƒ…æ„Ÿè¡¨è¾¾åº¦
                cfg_weight=0.8,               # ç›¸ä¼¼åº¦æƒé‡ï¼ˆé«˜ç›¸ä¼¼åº¦ï¼‰
                temperature=0.7               # éšæœºæ€§æ§åˆ¶
            )
            
            # ä¿å­˜ç”Ÿæˆçš„éŸ³é¢‘
            output_path = output_dir / f"cloned_from_existing_{i}.wav"
            ta.save(output_path, wav_tensor, model.sr)
            
            # è®¡ç®—éŸ³é¢‘æ—¶é•¿
            audio_duration = wav_tensor.shape[1] / model.sr
            
            print(f"  âœ… ç”ŸæˆæˆåŠŸ")
            print(f"  ğŸ“ ä¿å­˜è·¯å¾„: {output_path}")
            print(f"  ğŸ¼ éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f}ç§’")
            
            successful_generations += 1
            
        except Exception as e:
            print(f"  âŒ ç”Ÿæˆå¤±è´¥: {e}")
            continue
    
    print(f"\nğŸ‰ è¯­éŸ³å…‹éš†æ¼”ç¤ºå®Œæˆï¼")
    print(f"ğŸ“Š æˆåŠŸç”Ÿæˆ: {successful_generations}/{len(test_texts)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ¯ å‚è€ƒéŸ³é¢‘: {best_file}")
    
    # æä¾›è¿›ä¸€æ­¥çš„å»ºè®®
    print("\nğŸ’¡ è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®:")
    print("1. ğŸ“ å°è¯•ä½¿ç”¨è‡ªå·±å½•åˆ¶çš„é«˜è´¨é‡éŸ³é¢‘ä½œä¸ºå‚è€ƒ")
    print("2. ğŸ›ï¸  è°ƒæ•´å‚æ•°: cfg_weight (ç›¸ä¼¼åº¦), exaggeration (è¡¨è¾¾åº¦), temperature (éšæœºæ€§)")
    print("3. ğŸ“ ä½¿ç”¨æ›´é•¿æˆ–æ›´çŸ­çš„æ–‡æœ¬è¿›è¡Œæµ‹è¯•")
    print("4. ğŸ”„ å¤šæ¬¡ç”ŸæˆåŒä¸€æ–‡æœ¬ï¼Œè§‚å¯Ÿå˜åŒ–")
    
    print("\nğŸ›ï¸ å‚æ•°è¯´æ˜:")
    print("â€¢ cfg_weight=0.8 (é«˜ç›¸ä¼¼åº¦) - å¯è°ƒæ•´åˆ°0.5-0.9")
    print("â€¢ exaggeration=0.7 (ä¸­ç­‰è¡¨è¾¾) - å¯è°ƒæ•´åˆ°0.3-1.2") 
    print("â€¢ temperature=0.7 (ä¸­ç­‰éšæœº) - å¯è°ƒæ•´åˆ°0.5-1.0")
    
    print("\nğŸ“– ç›¸å…³æ–‡æ¡£:")
    print("â€¢ docs/è¯­éŸ³å…‹éš†å®Œæ•´æŒ‡å—.md - è¯¦ç»†ä½¿ç”¨æŒ‡å—")
    print("â€¢ examples/advanced/voice_cloning_tutorial.py - é«˜çº§æ•™ç¨‹")

if __name__ == "__main__":
    voice_cloning_demo_with_existing() 