

#!/usr/bin/env python3
"""
æœ€ç»ˆç‰ˆè¯­éŸ³å…‹éš†ç½‘é¡µç•Œé¢
è§£å†³é—®é¢˜ï¼šè¿›åº¦æ¡ä¸AIç”ŸæˆåŒæ­¥ã€å½•éŸ³éŸ³é¢‘åº“ç®¡ç†
"""

import gradio as gr
import torch
import torchaudio as ta
from chatterbox.tts import ChatterboxTTS
import os
import time
import librosa
import numpy as np
from pathlib import Path
import datetime
import json
import threading
from typing import Optional, List, Tuple

# å…¨å±€å˜é‡
model = None
model_info = {"name": "", "version": "", "device": ""}
temp_dir = Path("output/web_voice_cloning")
audio_library_dir = Path("output/audio_library")  # éŸ³é¢‘åº“ç›®å½•
temp_dir.mkdir(parents=True, exist_ok=True)
audio_library_dir.mkdir(parents=True, exist_ok=True)

# éŸ³é¢‘åº“ç´¢å¼•æ–‡ä»¶
audio_index_file = audio_library_dir / "audio_index.json"

def load_audio_index():
    """åŠ è½½éŸ³é¢‘åº“ç´¢å¼•"""
    if audio_index_file.exists():
        try:
            with open(audio_index_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_audio_index(index):
    """ä¿å­˜éŸ³é¢‘åº“ç´¢å¼•"""
    with open(audio_index_file, 'w', encoding='utf-8') as f:
        json.dump(index, f, ensure_ascii=False, indent=2)

def apply_torch_load_patch():
    """åº”ç”¨torch.loadè¡¥ä¸"""
    original_load = torch.load
    
    def patched_load(f, map_location=None, **kwargs):
        if map_location is None and not torch.cuda.is_available():
            map_location = torch.device('cpu')
        try:
            return original_load(f, map_location=map_location, **kwargs)
        except RuntimeError as e:
            if "CUDA" in str(e):
                return original_load(f, map_location=torch.device('cpu'), **kwargs)
            raise e
    
    torch.load = patched_load

def validate_and_process_audio(audio_input):
    """éªŒè¯å’Œå¤„ç†éŸ³é¢‘è¾“å…¥"""
    if audio_input is None:
        return None, "âŒ è¯·å…ˆå½•åˆ¶æˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"
    
    try:
        # å¤„ç†ä¸åŒçš„éŸ³é¢‘è¾“å…¥æ ¼å¼
        if isinstance(audio_input, tuple):
            # Gradioéº¦å…‹é£å½•éŸ³æ ¼å¼ (sample_rate, audio_data)
            sr, audio_data = audio_input
            audio_data = audio_data.astype(np.float32)
            
            # è½¬æ¢ä¸ºå•å£°é“
            if len(audio_data.shape) > 1:
                audio_data = audio_data.mean(axis=1)
            
            # éªŒè¯éŸ³é¢‘é•¿åº¦
            duration = len(audio_data) / sr
            if duration < 1.0:
                return None, "âŒ éŸ³é¢‘å¤ªçŸ­ï¼Œè¯·å½•åˆ¶è‡³å°‘1ç§’çš„éŸ³é¢‘"
            if duration > 30.0:
                return None, "âŒ éŸ³é¢‘å¤ªé•¿ï¼Œè¯·å½•åˆ¶ä¸è¶…è¿‡30ç§’çš„éŸ³é¢‘"
            
            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            timestamp = int(time.time())
            temp_audio_path = temp_dir / f"temp_audio_{timestamp}.wav"
            
            # ç¡®ä¿éŸ³é¢‘æ•°æ®åœ¨æ­£ç¡®èŒƒå›´å†…
            if np.max(np.abs(audio_data)) > 1.0:
                audio_data = audio_data / np.max(np.abs(audio_data)) * 0.95
            
            ta.save(temp_audio_path, torch.from_numpy(audio_data).unsqueeze(0), sr)
            return str(temp_audio_path), f"âœ… éŸ³é¢‘å¤„ç†æˆåŠŸï¼æ—¶é•¿: {duration:.2f}ç§’ï¼Œé‡‡æ ·ç‡: {sr}Hz"
            
        else:
            # ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
            if not os.path.exists(audio_input):
                return None, "âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨"
            
            # ä½¿ç”¨librosaåŠ è½½å’ŒéªŒè¯
            audio_data, sr = librosa.load(audio_input, sr=None)
            duration = len(audio_data) / sr
            
            if duration < 1.0:
                return None, "âŒ éŸ³é¢‘å¤ªçŸ­ï¼Œè¯·ä½¿ç”¨è‡³å°‘1ç§’çš„éŸ³é¢‘"
            if duration > 30.0:
                return None, "âŒ éŸ³é¢‘å¤ªé•¿ï¼Œè¯·ä½¿ç”¨ä¸è¶…è¿‡30ç§’çš„éŸ³é¢‘"
                
            return audio_input, f"âœ… éŸ³é¢‘éªŒè¯æˆåŠŸï¼æ—¶é•¿: {duration:.2f}ç§’ï¼Œé‡‡æ ·ç‡: {sr}Hz"
            
    except Exception as e:
        return None, f"âŒ éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}"

def save_recording_to_library(audio_input, custom_name: str = ""):
    """å°†å½•éŸ³ä¿å­˜åˆ°éŸ³é¢‘åº“"""
    if audio_input is None:
        return "âŒ è¯·å…ˆå½•åˆ¶éŸ³é¢‘", get_audio_library_list()
    
    try:
        # éªŒè¯å’Œå¤„ç†éŸ³é¢‘
        processed_path, status_msg = validate_and_process_audio(audio_input)
        if processed_path is None:
            return status_msg, get_audio_library_list()
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        if custom_name.strip():
            safe_name = "".join(c for c in custom_name if c.isalnum() or c in (' ', '-', '_')).strip()
            filename = f"{safe_name}_{timestamp}.wav"
        else:
            filename = f"å½•éŸ³_{timestamp}.wav"
        
        # ä¿å­˜åˆ°éŸ³é¢‘åº“
        library_path = audio_library_dir / filename
        
        if isinstance(audio_input, tuple):
            # é‡æ–°ä¿å­˜å½•éŸ³æ•°æ®åˆ°éŸ³é¢‘åº“
            sr, audio_data = audio_input
            audio_data = audio_data.astype(np.float32)
            if len(audio_data.shape) > 1:
                audio_data = audio_data.mean(axis=1)
            if np.max(np.abs(audio_data)) > 1.0:
                audio_data = audio_data / np.max(np.abs(audio_data)) * 0.95
            ta.save(library_path, torch.from_numpy(audio_data).unsqueeze(0), sr)
        else:
            # å¤åˆ¶æ–‡ä»¶åˆ°éŸ³é¢‘åº“
            import shutil
            shutil.copy2(processed_path, library_path)
        
        # æ›´æ–°éŸ³é¢‘åº“ç´¢å¼•
        index = load_audio_index()
        audio_info = {
            "filename": filename,
            "path": str(library_path),
            "created_time": timestamp,
            "name": custom_name.strip() if custom_name.strip() else f"å½•éŸ³_{timestamp}",
            "duration": librosa.get_duration(path=str(library_path)),
            "sample_rate": librosa.get_samplerate(str(library_path))
        }
        index[filename] = audio_info
        save_audio_index(index)
        
        success_msg = f"""âœ… å½•éŸ³å·²ä¿å­˜åˆ°éŸ³é¢‘åº“ï¼

ğŸ“‹ ä¿å­˜ä¿¡æ¯:
â€¢ ğŸµ åç§°: {audio_info['name']}
â€¢ ğŸ“ æ–‡ä»¶: {filename}
â€¢ â±ï¸ æ—¶é•¿: {audio_info['duration']:.2f}ç§’
â€¢ ğŸ“ˆ é‡‡æ ·ç‡: {audio_info['sample_rate']}Hz
â€¢ ğŸ• ä¿å­˜æ—¶é—´: {timestamp}

ğŸ’¡ ç°åœ¨å¯ä»¥åœ¨å†å²å½•éŸ³ä¸­é€‰æ‹©ä½¿ç”¨æ­¤éŸ³é¢‘ï¼"""
        
        return success_msg, get_audio_library_list()
        
    except Exception as e:
        return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}", get_audio_library_list()

def get_audio_library_list():
    """è·å–éŸ³é¢‘åº“åˆ—è¡¨"""
    index = load_audio_index()
    if not index:
        return ["æš‚æ— å†å²å½•éŸ³"]
    
    # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åˆ—
    sorted_items = sorted(index.items(), key=lambda x: x[1]['created_time'], reverse=True)
    return [f"{item['name']} ({item['duration']:.1f}s)" for _, item in sorted_items]

def load_audio_from_library(selected_audio: str):
    """ä»éŸ³é¢‘åº“åŠ è½½é€‰å®šçš„éŸ³é¢‘"""
    if not selected_audio or selected_audio == "æš‚æ— å†å²å½•éŸ³":
        return None, "è¯·é€‰æ‹©æœ‰æ•ˆçš„å†å²å½•éŸ³"
    
    try:
        index = load_audio_index()
        
        # æ ¹æ®æ˜¾ç¤ºåç§°æŸ¥æ‰¾æ–‡ä»¶
        for filename, info in index.items():
            display_name = f"{info['name']} ({info['duration']:.1f}s)"
            if display_name == selected_audio:
                audio_path = info['path']
                if os.path.exists(audio_path):
                    # åˆ†æé€‰å®šçš„éŸ³é¢‘
                    audio_data, sr = librosa.load(audio_path, sr=None)
                    duration = len(audio_data) / sr
                    max_amplitude = np.max(np.abs(audio_data))
                    
                    analysis = f"""ğŸ“š æ¥è‡ªéŸ³é¢‘åº“: {info['name']}

ğŸ“Š éŸ³é¢‘åˆ†æ:
â€¢ â±ï¸ æ—¶é•¿: {duration:.2f}ç§’
â€¢ ğŸ“ˆ é‡‡æ ·ç‡: {sr}Hz
â€¢ ğŸ”Š æœ€å¤§éŸ³é‡: {max_amplitude:.3f}
â€¢ ğŸ“… å½•åˆ¶æ—¶é—´: {info['created_time']}
â€¢ ğŸ“ æ–‡ä»¶: {filename}

âœ… å·²åŠ è½½å†å²å½•éŸ³ï¼Œå¯ä»¥å¼€å§‹è¯­éŸ³å…‹éš†ï¼"""
                    
                    return audio_path, analysis
                else:
                    return None, f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}"
        
        return None, "âŒ æœªæ‰¾åˆ°å¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶"
        
    except Exception as e:
        return None, f"âŒ åŠ è½½å¤±è´¥: {str(e)}"

def analyze_uploaded_audio(audio_input):
    """åˆ†æä¸Šä¼ çš„éŸ³é¢‘å¹¶è¿”å›é¢„è§ˆä¿¡æ¯"""
    if audio_input is None:
        return None, "è¯·å…ˆå½•åˆ¶æˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"
    
    try:
        processed_path, status_msg = validate_and_process_audio(audio_input)
        if processed_path is None:
            return None, status_msg
        
        # åˆ†æéŸ³é¢‘ä¿¡æ¯
        if isinstance(audio_input, tuple):
            sr, audio_data = audio_input
            audio_data = audio_data.astype(np.float32)
            if len(audio_data.shape) > 1:
                audio_data = audio_data.mean(axis=1)
            duration = len(audio_data) / sr
            max_amplitude = np.max(np.abs(audio_data))
        else:
            audio_data, sr = librosa.load(audio_input, sr=None)
            duration = len(audio_data) / sr
            max_amplitude = np.max(np.abs(audio_data))
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        quality = "ä¼˜ç§€" if 3 <= duration <= 10 and sr >= 16000 and max_amplitude > 0.1 else "å¯ç”¨"
        analysis = f"""
ğŸ“Š éŸ³é¢‘åˆ†æç»“æœ:
â€¢ â±ï¸ æ—¶é•¿: {duration:.2f}ç§’
â€¢ ğŸ“ˆ é‡‡æ ·ç‡: {sr}Hz  
â€¢ ğŸ”Š æœ€å¤§éŸ³é‡: {max_amplitude:.3f}
â€¢ ğŸµ è´¨é‡è¯„ä¼°: {quality}

ğŸ’¡ å»ºè®®:
â€¢ æœ€ä½³æ—¶é•¿: 3-10ç§’
â€¢ æ¨èé‡‡æ ·ç‡: â‰¥16kHz
â€¢ éŸ³é‡æ°´å¹³: >0.1 (å½“å‰: {max_amplitude:.3f})
â€¢ å½•éŸ³ç¯å¢ƒ: å®‰é™æ— èƒŒæ™¯å™ªéŸ³

ğŸ’¾ æç¤º: ç‚¹å‡»"ä¿å­˜åˆ°éŸ³é¢‘åº“"å¯å°†æ­¤å½•éŸ³ä¿å­˜ä¾›ä»¥åä½¿ç”¨
"""
        
        return processed_path, analysis
        
    except Exception as e:
        return None, f"âŒ éŸ³é¢‘åˆ†æå¤±è´¥: {str(e)}"

def load_model_with_info():
    """åŠ è½½TTSæ¨¡å‹å¹¶è¿”å›è¯¦ç»†ä¿¡æ¯"""
    global model, model_info
    
    if model is None:
        apply_torch_load_patch()
        try:
            # æ˜¾ç¤ºåŠ è½½å¼€å§‹
            yield "ğŸ”„ æ­£åœ¨åˆå§‹åŒ–AIæ¨¡å‹..."
            
            # åŠ è½½æ¨¡å‹
            model = ChatterboxTTS.from_pretrained(device="cpu")
            
            # è·å–æ¨¡å‹ä¿¡æ¯
            device = "CPU (Apple Silicon MPS)" if torch.backends.mps.is_available() else "CPU"
            model_info = {
                "name": "ChatterboxTTS",
                "version": "v1.0",
                "device": device,
                "precision": "float32",
                "memory": "çº¦2-4GB"
            }
            
            success_msg = f"""âœ… AIæ¨¡å‹åŠ è½½æˆåŠŸï¼

ğŸ“‹ æ¨¡å‹è¯¦ç»†ä¿¡æ¯:
â€¢ ğŸ¤– æ¨¡å‹åç§°: {model_info['name']}
â€¢ ğŸ“¦ ç‰ˆæœ¬: {model_info['version']}
â€¢ ğŸ’» è¿è¡Œè®¾å¤‡: {model_info['device']}
â€¢ ğŸ¯ ç²¾åº¦: {model_info['precision']}
â€¢ ğŸ’¾ å†…å­˜ä½¿ç”¨: {model_info['memory']}

ğŸ­ ç³»ç»Ÿå·²å°±ç»ªï¼Œç°åœ¨å¯ä»¥å¼€å§‹è¯­éŸ³å…‹éš†äº†ï¼"""
            
            yield success_msg
            
        except Exception as e:
            error_msg = f"""âŒ æ¨¡å‹åŠ è½½å¤±è´¥!

ğŸ” é”™è¯¯ä¿¡æ¯: {str(e)}

ğŸ’¡ è§£å†³å»ºè®®:
â€¢ æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼ˆé¦–æ¬¡ä½¿ç”¨éœ€ä¸‹è½½æ¨¡å‹ï¼‰
â€¢ ç¡®ä¿æœ‰è¶³å¤Ÿå†…å­˜ç©ºé—´ï¼ˆéœ€è¦2-4GBï¼‰
â€¢ é‡å¯ç¨‹åºåé‡è¯•
â€¢ æ£€æŸ¥CUDA/MPSè®¾å¤‡çŠ¶æ€"""
            yield error_msg
    else:
        yield f"""âœ… AIæ¨¡å‹å·²å°±ç»ªï¼

ğŸ“‹ å½“å‰æ¨¡å‹ä¿¡æ¯:
â€¢ ğŸ¤– æ¨¡å‹åç§°: {model_info['name']}
â€¢ ğŸ’» è¿è¡Œè®¾å¤‡: {model_info['device']}
â€¢ ğŸ¯ çŠ¶æ€: å·²åŠ è½½å¹¶å‡†å¤‡å°±ç»ª"""

def enhanced_voice_clone_v2(audio_file, text, cfg_weight, exaggeration, temperature, progress=gr.Progress()):
    """å¢å¼ºçš„è¯­éŸ³å…‹éš†å‡½æ•°V2ï¼Œæ”¹è¿›è¿›åº¦åŒæ­¥"""
    global model
    
    # æ£€æŸ¥æ¨¡å‹
    if model is None:
        return None, "âŒ è¯·å…ˆç‚¹å‡»'ğŸ”§ åŠ è½½æ¨¡å‹'æŒ‰é’®ï¼"
    
    # æ£€æŸ¥è¾“å…¥
    if audio_file is None:
        return None, "âŒ è¯·å…ˆå½•åˆ¶ã€ä¸Šä¼ æˆ–ä»éŸ³é¢‘åº“é€‰æ‹©å‚è€ƒéŸ³é¢‘ï¼"
    
    if not text.strip():
        return None, "âŒ è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬å†…å®¹ï¼"
    
    try:
        # æ­¥éª¤1: éªŒè¯éŸ³é¢‘ (5%)
        progress(0.05, desc="ğŸ” éªŒè¯éŸ³é¢‘æ–‡ä»¶...")
        processed_audio, validation_msg = validate_and_process_audio(audio_file)
        if processed_audio is None:
            return None, f"âŒ éŸ³é¢‘éªŒè¯å¤±è´¥: {validation_msg}"
        
        # æ­¥éª¤2: å‡†å¤‡å‚æ•° (10%)
        progress(0.10, desc="âš™ï¸ å‡†å¤‡ç”Ÿæˆå‚æ•°...")
        time.sleep(0.3)
        
        # æ­¥éª¤3: å¼€å§‹AIç”Ÿæˆ (15% - 85%)
        progress(0.15, desc="ğŸ­ å¼€å§‹AIè¯­éŸ³å…‹éš†...")
        
        # åœ¨è¿™é‡Œæˆ‘ä»¬éœ€è¦åˆ†é˜¶æ®µæ›´æ–°è¿›åº¦
        def update_generation_progress():
            """æ¨¡æ‹ŸAIç”Ÿæˆè¿‡ç¨‹çš„è¿›åº¦æ›´æ–°"""
            stages = [
                (0.20, "ğŸ§  AIæ­£åœ¨åˆ†æå‚è€ƒéŸ³é¢‘..."),
                (0.35, "ğŸµ æå–å£°éŸ³ç‰¹å¾..."), 
                (0.50, "ğŸ“ å¤„ç†æ–‡æœ¬å†…å®¹..."),
                (0.65, "ğŸ­ å¼€å§‹è¯­éŸ³åˆæˆ..."),
                (0.80, "ğŸ”„ ä¼˜åŒ–éŸ³é¢‘è´¨é‡...")
            ]
            
            for prog, desc in stages:
                progress(prog, desc=desc)
                time.sleep(0.8)  # ç»™ç”¨æˆ·çœ‹åˆ°è¿›åº¦çš„æ—¶é—´
        
        # åœ¨åå°æ›´æ–°è¿›åº¦
        progress_thread = threading.Thread(target=update_generation_progress)
        progress_thread.start()
        
        # æ‰§è¡Œè¯­éŸ³å…‹éš†ï¼ˆè¿™æ˜¯å®é™…çš„AIè®¡ç®—ï¼‰
        start_time = time.time()
        wav_tensor = model.generate(
            text=text,
            audio_prompt_path=processed_audio,
            cfg_weight=cfg_weight,
            exaggeration=exaggeration,
            temperature=temperature
        )
        generation_time = time.time() - start_time
        
        # ç­‰å¾…è¿›åº¦çº¿ç¨‹å®Œæˆ
        progress_thread.join()
        
        # æ­¥éª¤4: ä¿å­˜ç»“æœ (90%)
        progress(0.90, desc="ğŸ’¾ ä¿å­˜éŸ³é¢‘æ–‡ä»¶...")
        timestamp = int(time.time())
        output_path = temp_dir / f"cloned_voice_{timestamp}.wav"
        ta.save(output_path, wav_tensor, model.sr)
        
        # æ­¥éª¤5: ç”ŸæˆæŠ¥å‘Š (95%)
        progress(0.95, desc="ğŸ“Š ç”Ÿæˆç»“æœæŠ¥å‘Š...")
        audio_duration = wav_tensor.shape[1] / model.sr
        file_size = os.path.getsize(output_path) / 1024  # KB
        
        # å®Œæˆ (100%)
        progress(1.0, desc="âœ… è¯­éŸ³å…‹éš†å®Œæˆï¼")
        
        result_info = f"""ğŸ‰ è¯­éŸ³å…‹éš†æˆåŠŸå®Œæˆï¼

ğŸ“Š ç”Ÿæˆç»Ÿè®¡:
â€¢ ğŸ¼ éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f}ç§’
â€¢ ğŸ“ æ–‡ä»¶å¤§å°: {file_size:.1f}KB
â€¢ â±ï¸ ç”Ÿæˆè€—æ—¶: {generation_time:.1f}ç§’
â€¢ ğŸ’¾ ä¿å­˜è·¯å¾„: {output_path.name}
â€¢ ğŸ• å®Œæˆæ—¶é—´: {time.strftime('%H:%M:%S')}

âš™ï¸ ä½¿ç”¨å‚æ•°:
â€¢ ğŸ¯ ç›¸ä¼¼åº¦æ§åˆ¶: {cfg_weight} {'(é«˜ç›¸ä¼¼åº¦)' if cfg_weight >= 0.8 else '(ä¸­ç­‰ç›¸ä¼¼åº¦)' if cfg_weight >= 0.6 else '(ä½ç›¸ä¼¼åº¦)'}
â€¢ ğŸ­ æƒ…æ„Ÿè¡¨è¾¾åº¦: {exaggeration} {'(ä¸°å¯Œè¡¨è¾¾)' if exaggeration >= 1.0 else '(è‡ªç„¶è¡¨è¾¾)' if exaggeration >= 0.7 else '(å¹³æ·¡è¡¨è¾¾)'}
â€¢ ğŸ² éšæœºæ€§æ§åˆ¶: {temperature} {'(é«˜å˜åŒ–)' if temperature >= 0.9 else '(å¹³è¡¡)' if temperature >= 0.7 else '(ç¨³å®š)'}

ğŸ’¡ æç¤º: å¯è°ƒæ•´å‚æ•°é‡æ–°ç”Ÿæˆä»¥è·å¾—ä¸åŒæ•ˆæœï¼
ğŸµ å¯ä»¥ä¸‹è½½éŸ³é¢‘æ–‡ä»¶ä¿å­˜åˆ°æœ¬åœ°ä½¿ç”¨"""
        
        return str(output_path), result_info
        
    except Exception as e:
        error_detail = str(e)
        if "index out of range" in error_detail:
            error_msg = f"""âŒ è¯­éŸ³å…‹éš†å¤±è´¥: éŸ³é¢‘å¤„ç†é”™è¯¯

ğŸ” å…·ä½“é”™è¯¯: {error_detail}

ğŸ’¡ è§£å†³æ–¹æ¡ˆ:
â€¢ å°è¯•ä½¿ç”¨æ›´é•¿çš„å‚è€ƒéŸ³é¢‘ï¼ˆ3-10ç§’ï¼‰
â€¢ ç¡®ä¿éŸ³é¢‘æ ¼å¼æ­£ç¡®ï¼ˆWAV/MP3/FLACï¼‰
â€¢ æ£€æŸ¥éŸ³é¢‘è´¨é‡ï¼ˆæ— æŸåã€æ— ç©ºç™½ï¼‰
â€¢ é‡æ–°å½•åˆ¶æˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
â€¢ è°ƒæ•´å‚æ•°åé‡è¯•ï¼ˆé™ä½cfg_weightåˆ°0.7ï¼‰
â€¢ å°è¯•ä»éŸ³é¢‘åº“é€‰æ‹©å…¶ä»–å½•éŸ³"""
        else:
            error_msg = f"""âŒ è¯­éŸ³å…‹éš†å¤±è´¥: {error_detail}

ğŸ’¡ å»ºè®®:
â€¢ æ£€æŸ¥å‚è€ƒéŸ³é¢‘è´¨é‡
â€¢ å°è¯•è°ƒæ•´å‚æ•°è®¾ç½®
â€¢ é‡å¯åŠ è½½æ¨¡å‹
â€¢ æŸ¥çœ‹ç»ˆç«¯è¾“å‡ºè·å–æ›´å¤šä¿¡æ¯
â€¢ ç”Ÿæˆè€—æ—¶è¾ƒé•¿æ˜¯æ­£å¸¸ç°è±¡ï¼Œè¯·è€å¿ƒç­‰å¾…"""
        
        return None, error_msg

def delete_audio_from_library(selected_audio: str):
    """ä»éŸ³é¢‘åº“åˆ é™¤é€‰å®šçš„éŸ³é¢‘"""
    if not selected_audio or selected_audio == "æš‚æ— å†å²å½•éŸ³":
        return "è¯·é€‰æ‹©è¦åˆ é™¤çš„å½•éŸ³", get_audio_library_list()
    
    try:
        index = load_audio_index()
        
        # æŸ¥æ‰¾è¦åˆ é™¤çš„æ–‡ä»¶
        for filename, info in index.items():
            display_name = f"{info['name']} ({info['duration']:.1f}s)"
            if display_name == selected_audio:
                # åˆ é™¤æ–‡ä»¶
                audio_path = Path(info['path'])
                if audio_path.exists():
                    audio_path.unlink()
                
                # ä»ç´¢å¼•ä¸­åˆ é™¤
                del index[filename]
                save_audio_index(index)
                
                return f"âœ… å·²åˆ é™¤å½•éŸ³: {info['name']}", get_audio_library_list()
        
        return "âŒ æœªæ‰¾åˆ°è¦åˆ é™¤çš„å½•éŸ³", get_audio_library_list()
        
    except Exception as e:
        return f"âŒ åˆ é™¤å¤±è´¥: {str(e)}", get_audio_library_list()

def create_final_interface():
    """åˆ›å»ºæœ€ç»ˆç‰ˆç½‘é¡µç•Œé¢"""
    
    custom_css = """
    .gradio-container {
        max-width: 1400px !important;
        margin: auto !important;
    }
    .gr-button {
        background: linear-gradient(45deg, #667eea, #764ba2) !important;
        border: none !important;
        color: white !important;
        transition: all 0.3s ease !important;
    }
    .gr-button:hover {
        transform: translateY(-2px) !important;
        box-shadow: 0 5px 15px rgba(0,0,0,0.2) !important;
    }
    .audio-library {
        border: 2px dashed #4CAF50;
        border-radius: 10px;
        padding: 15px;
        background: rgba(76, 175, 80, 0.1);
    }
    .progress-info {
        background: linear-gradient(135deg, #667eea, #764ba2);
        color: white;
        padding: 10px;
        border-radius: 8px;
        margin: 10px 0;
    }
    """
    
    with gr.Blocks(css=custom_css, title="ğŸ­ æœ€ç»ˆç‰ˆè¯­éŸ³å…‹éš†", theme=gr.themes.Soft()) as demo:
        
        gr.HTML("""
        <div style="text-align: center; margin: 20px;">
            <h1>ğŸ­ æœ€ç»ˆç‰ˆè¯­éŸ³å…‹éš†ç³»ç»Ÿ</h1>
            <p style="font-size: 18px; color: #666;">
                AIé©±åŠ¨ | è¿›åº¦åŒæ­¥ | éŸ³é¢‘åº“ç®¡ç† | ä¸“ä¸šçº§è¯­éŸ³å…‹éš†
            </p>
        </div>
        """)
        
        with gr.Row():
            # å·¦ä¾§ï¼šè¾“å…¥å’ŒéŸ³é¢‘åº“
            with gr.Column(scale=1):
                gr.HTML("<h3>ğŸ™ï¸ æ­¥éª¤1: å½•åˆ¶/ä¸Šä¼ /é€‰æ‹©éŸ³é¢‘</h3>")
                
                # éŸ³é¢‘è¾“å…¥
                audio_input = gr.Audio(
                    label="å½•åˆ¶æ–°éŸ³é¢‘æˆ–ä¸Šä¼ æ–‡ä»¶",
                    type="filepath",
                    sources=["upload", "microphone"],
                    show_label=True
                )
                
                # éŸ³é¢‘åº“ç®¡ç†
                with gr.Group():
                    gr.HTML("<h4>ğŸ“š éŸ³é¢‘åº“ç®¡ç†</h4>")
                    with gr.Row():
                        save_name = gr.Textbox(
                            label="è‡ªå®šä¹‰åç§°ï¼ˆå¯é€‰ï¼‰",
                            placeholder="ä¸ºå½•éŸ³èµ·ä¸ªåå­—...",
                            scale=2
                        )
                        save_to_library_btn = gr.Button("ğŸ’¾ ä¿å­˜åˆ°éŸ³é¢‘åº“", variant="secondary", scale=1)
                    
                    with gr.Row():
                        library_dropdown = gr.Dropdown(
                            choices=get_audio_library_list(),
                            label="é€‰æ‹©å†å²å½•éŸ³",
                            value=None,
                            allow_custom_value=False,
                            scale=2
                        )
                        refresh_library_btn = gr.Button("ğŸ”„", variant="secondary", scale=0)
                    
                    with gr.Row():
                        load_from_library_btn = gr.Button("ğŸ“‚ åŠ è½½é€‰å®šå½•éŸ³", variant="secondary", scale=1)
                        delete_from_library_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤é€‰å®šå½•éŸ³", variant="secondary", scale=1)
                
                # éŸ³é¢‘åˆ†æ
                with gr.Row():
                    analyze_btn = gr.Button("ğŸ” åˆ†æéŸ³é¢‘", variant="secondary")
                    preview_audio = gr.Audio(
                        label="éŸ³é¢‘é¢„è§ˆ",
                        type="filepath",
                        interactive=False
                    )
                
                audio_status = gr.Textbox(
                    label="éŸ³é¢‘åˆ†æç»“æœ",
                    lines=10,
                    interactive=False,
                    placeholder="å½•åˆ¶/ä¸Šä¼ /é€‰æ‹©éŸ³é¢‘åï¼Œç‚¹å‡»'åˆ†æéŸ³é¢‘'æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯..."
                )
                
                library_status = gr.Textbox(
                    label="éŸ³é¢‘åº“æ“ä½œçŠ¶æ€",
                    lines=3,
                    interactive=False,
                    placeholder="éŸ³é¢‘åº“æ“ä½œç»“æœå°†åœ¨è¿™é‡Œæ˜¾ç¤º..."
                )
                
                gr.HTML("<h3>ğŸ“ æ­¥éª¤2: è¾“å…¥åˆæˆæ–‡æœ¬</h3>")
                text_input = gr.Textbox(
                    label="è¦åˆæˆçš„æ–‡æœ¬å†…å®¹",
                    placeholder="è¯·è¾“å…¥æ‚¨æƒ³è¦å…‹éš†è¯­éŸ³è¯´çš„å†…å®¹...\nç¤ºä¾‹: Hello, this is a voice cloning demonstration.",
                    lines=3,
                    max_lines=5
                )
                
                gr.HTML("<h3>âš™ï¸ æ­¥éª¤3: è°ƒæ•´å…‹éš†å‚æ•°</h3>")
                
                with gr.Row():
                    cfg_weight = gr.Slider(
                        minimum=0.1, maximum=1.0, value=0.8, step=0.05,
                        label="ğŸ¯ ç›¸ä¼¼åº¦æ§åˆ¶",
                        info="0.8-0.9: é«˜ç›¸ä¼¼åº¦ | 0.6-0.7: å¹³è¡¡ | 0.4-0.5: åˆ›æ„"
                    )
                
                with gr.Row():
                    exaggeration = gr.Slider(
                        minimum=0.1, maximum=2.0, value=0.7, step=0.05,
                        label="ğŸ­ æƒ…æ„Ÿè¡¨è¾¾åº¦",
                        info="0.4-0.6: å¹³æ·¡ | 0.7-0.9: è‡ªç„¶ | 1.0+: ä¸°å¯Œ"
                    )
                
                with gr.Row():
                    temperature = gr.Slider(
                        minimum=0.1, maximum=2.0, value=0.7, step=0.05,
                        label="ğŸ² éšæœºæ€§æ§åˆ¶",
                        info="0.5-0.6: ç¨³å®š | 0.7-0.8: å¹³è¡¡ | 0.9+: å¤šæ ·"
                    )
            
            # å³ä¾§ï¼šæ§åˆ¶å’Œè¾“å‡ºåŒºåŸŸ
            with gr.Column(scale=1):
                gr.HTML("<h3>ğŸš€ æ­¥éª¤4: æ¨¡å‹ç®¡ç†</h3>")
                
                load_btn = gr.Button("ğŸ”§ åŠ è½½AIæ¨¡å‹", variant="secondary", size="lg")
                model_status = gr.Textbox(
                    label="AIæ¨¡å‹çŠ¶æ€ä¸ä¿¡æ¯",
                    lines=8,
                    value="ç‚¹å‡»'åŠ è½½AIæ¨¡å‹'å¼€å§‹åˆå§‹åŒ–...",
                    interactive=False
                )
                
                gr.HTML("<h3>ğŸ­ æ­¥éª¤5: å¼€å§‹å…‹éš†</h3>")
                clone_btn = gr.Button("ğŸ­ å¼€å§‹è¯­éŸ³å…‹éš†", variant="primary", size="lg")
                
                gr.HTML("""
                <div class="progress-info">
                    <h4>âš¡ è¿›åº¦åŒæ­¥ä¼˜åŒ–</h4>
                    <p>â€¢ å‰å°è¿›åº¦æ¡ä¸AIç”Ÿæˆå®æ—¶åŒæ­¥</p>
                    <p>â€¢ è¯¦ç»†æ˜¾ç¤ºæ¯ä¸ªå¤„ç†é˜¶æ®µ</p>
                    <p>â€¢ å‡†ç¡®åæ˜ å®é™…ç”Ÿæˆè¿›åº¦</p>
                </div>
                """)
                
                gr.HTML("<h3>ğŸµ å…‹éš†ç»“æœ</h3>")
                output_audio = gr.Audio(
                    label="ç”Ÿæˆçš„è¯­éŸ³",
                    type="filepath",
                    interactive=False
                )
                
                result_info = gr.Textbox(
                    label="è¯¦ç»†ç»“æœä¿¡æ¯",
                    lines=15,
                    interactive=False,
                    placeholder="ç‚¹å‡»'å¼€å§‹è¯­éŸ³å…‹éš†'ç”Ÿæˆç»“æœ...",
                    show_copy_button=True
                )
        
        # å¿«é€Ÿç¤ºä¾‹å’Œå‚æ•°é¢„è®¾
        gr.HTML("<hr><h3>ğŸ’¡ å¿«é€Ÿç¤ºä¾‹ä¸å‚æ•°é¢„è®¾</h3>")
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.HTML("<h4>ğŸ“ æ–‡æœ¬ç¤ºä¾‹</h4>")
                examples = gr.Examples(
                    examples=[
                        ["Hello, this is a voice cloning test.", 0.8, 0.7, 0.7],
                        ["Good morning! How are you today?", 0.9, 0.5, 0.6],
                        ["Welcome to our amazing voice cloning service!", 0.7, 1.0, 0.8],
                        ["Thank you for trying out this advanced technology.", 0.8, 0.6, 0.5]
                    ],
                    inputs=[text_input, cfg_weight, exaggeration, temperature],
                    label="ç‚¹å‡»ç¤ºä¾‹å¿«é€Ÿè®¾ç½®"
                )
            
            with gr.Column(scale=1):
                gr.HTML("<h4>ğŸ›ï¸ å‚æ•°é¢„è®¾</h4>")
                with gr.Row():
                    preset_high_similarity = gr.Button("ğŸ¯ é«˜ç›¸ä¼¼åº¦", variant="secondary")
                    preset_natural = gr.Button("ğŸ­ è‡ªç„¶è¡¨è¾¾", variant="secondary")
                    preset_creative = gr.Button("ğŸ¨ åˆ›æ„é£æ ¼", variant="secondary")
                    preset_stable = gr.Button("ğŸ”’ ç¨³å®šè¾“å‡º", variant="secondary")
        
        # ä½¿ç”¨è¯´æ˜
        with gr.Accordion("ğŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜", open=False):
            gr.HTML("""
            <div style="padding: 20px; background: #f8f9fa; border-radius: 10px;">
                <h4>ğŸ¯ å®Œæ•´ä½¿ç”¨æµç¨‹:</h4>
                <ol>
                    <li><strong>å½•åˆ¶/ä¸Šä¼ /é€‰æ‹©éŸ³é¢‘</strong>: ä½¿ç”¨éº¦å…‹é£å½•åˆ¶ã€ä¸Šä¼ æ–‡ä»¶æˆ–ä»éŸ³é¢‘åº“é€‰æ‹©</li>
                    <li><strong>éŸ³é¢‘åº“ç®¡ç†</strong>: ä¿å­˜å½•éŸ³åˆ°åº“ä¸­ï¼Œç®¡ç†å†å²å½•éŸ³</li>
                    <li><strong>åˆ†æéŸ³é¢‘</strong>: éªŒè¯éŸ³é¢‘è´¨é‡å’Œæ ¼å¼</li>
                    <li><strong>è¾“å…¥æ–‡æœ¬</strong>: è¾“å…¥æƒ³è¦åˆæˆçš„å†…å®¹</li>
                    <li><strong>è°ƒæ•´å‚æ•°</strong>: æ ¹æ®éœ€è¦è°ƒæ•´ä¸‰ä¸ªæ ¸å¿ƒå‚æ•°</li>
                    <li><strong>åŠ è½½æ¨¡å‹</strong>: åˆå§‹åŒ–AIæ¨¡å‹</li>
                    <li><strong>å¼€å§‹å…‹éš†</strong>: æ‰§è¡Œè¯­éŸ³å…‹éš†ï¼Œäº«å—åŒæ­¥è¿›åº¦åé¦ˆ</li>
                </ol>
                
                <h4>ğŸ“š éŸ³é¢‘åº“åŠŸèƒ½:</h4>
                <ul>
                    <li><strong>è‡ªåŠ¨ä¿å­˜</strong>: å½•åˆ¶çš„éŸ³é¢‘å¯ä»¥ä¿å­˜åˆ°åº“ä¸­é‡å¤ä½¿ç”¨</li>
                    <li><strong>è‡ªå®šä¹‰å‘½å</strong>: ä¸ºæ¯ä¸ªå½•éŸ³è®¾ç½®æœ‰æ„ä¹‰çš„åç§°</li>
                    <li><strong>å†å²ç®¡ç†</strong>: æŸ¥çœ‹ã€é€‰æ‹©ã€åˆ é™¤å†å²å½•éŸ³</li>
                    <li><strong>å¿«é€ŸåŠ è½½</strong>: ä¸€é”®åŠ è½½ä¹‹å‰ä¿å­˜çš„é«˜è´¨é‡å½•éŸ³</li>
                </ul>
                
                <h4>âš¡ è¿›åº¦åŒæ­¥æ”¹è¿›:</h4>
                <ul>
                    <li><strong>çœŸå®åæ˜ </strong>: è¿›åº¦æ¡ä¸AIç”Ÿæˆè¿‡ç¨‹å®æ—¶åŒæ­¥</li>
                    <li><strong>é˜¶æ®µæ˜¾ç¤º</strong>: è¯¦ç»†æ˜¾ç¤ºæ¯ä¸ªå¤„ç†é˜¶æ®µ</li>
                    <li><strong>æ—¶é—´ä¼°ç®—</strong>: æ˜¾ç¤ºå®é™…ç”Ÿæˆè€—æ—¶</li>
                    <li><strong>ç”¨æˆ·å‹å¥½</strong>: è®©ç”¨æˆ·äº†è§£çœŸå®çš„å¤„ç†è¿›åº¦</li>
                </ul>
                
                <h4>âš ï¸ é‡è¦æé†’:</h4>
                <p>â€¢ AIè¯­éŸ³ç”Ÿæˆéœ€è¦ä¸€å®šæ—¶é—´ï¼Œåå°samplingè¿›åº¦æ˜¯æ­£å¸¸ç°è±¡<br>
                â€¢ è¯·è€å¿ƒç­‰å¾…ç”Ÿæˆå®Œæˆï¼Œé¿å…é‡å¤ç‚¹å‡»æŒ‰é’®<br>
                â€¢ ä»…ç”¨äºåˆæ³•å’Œé“å¾·ç›®çš„ï¼Œä¿æŠ¤ä»–äººéšç§æƒç›Š</p>
            </div>
            """)
        
        # äº‹ä»¶ç»‘å®š
        
        # æ¨¡å‹åŠ è½½
        load_btn.click(
            fn=load_model_with_info,
            outputs=model_status
        )
        
        # éŸ³é¢‘åˆ†æ
        analyze_btn.click(
            fn=analyze_uploaded_audio,
            inputs=audio_input,
            outputs=[preview_audio, audio_status]
        )
        
        # éŸ³é¢‘åº“æ“ä½œ
        save_to_library_btn.click(
            fn=save_recording_to_library,
            inputs=[audio_input, save_name],
            outputs=[library_status, library_dropdown]
        )
        
        refresh_library_btn.click(
            fn=lambda: gr.Dropdown(choices=get_audio_library_list(), value=None),
            outputs=library_dropdown
        )
        
        load_from_library_btn.click(
            fn=load_audio_from_library,
            inputs=library_dropdown,
            outputs=[preview_audio, audio_status]
        )
        
        delete_from_library_btn.click(
            fn=delete_audio_from_library,
            inputs=library_dropdown,
            outputs=[library_status, library_dropdown]
        )
        
        # è¯­éŸ³å…‹éš†
        clone_btn.click(
            fn=enhanced_voice_clone_v2,
            inputs=[audio_input, text_input, cfg_weight, exaggeration, temperature],
            outputs=[output_audio, result_info]
        )
        
        # å‚æ•°é¢„è®¾æŒ‰é’®
        def set_high_similarity():
            return 0.9, 0.5, 0.6
        
        def set_natural():
            return 0.8, 0.7, 0.7
        
        def set_creative():
            return 0.6, 1.0, 0.9
        
        def set_stable():
            return 0.8, 0.6, 0.5
        
        preset_high_similarity.click(
            fn=set_high_similarity,
            outputs=[cfg_weight, exaggeration, temperature]
        )
        
        preset_natural.click(
            fn=set_natural,
            outputs=[cfg_weight, exaggeration, temperature]
        )
        
        preset_creative.click(
            fn=set_creative,
            outputs=[cfg_weight, exaggeration, temperature]
        )
        
        preset_stable.click(
            fn=set_stable,
            outputs=[cfg_weight, exaggeration, temperature]
        )
    
    return demo

def main():
    """å¯åŠ¨æœ€ç»ˆç‰ˆç½‘é¡µç•Œé¢"""
    print("ğŸ­ æœ€ç»ˆç‰ˆè¯­éŸ³å…‹éš†ç½‘é¡µç•Œé¢")
    print("=" * 60)
    print("ğŸ¯ é—®é¢˜è§£å†³:")
    print("  â€¢ âœ… è¿›åº¦æ¡ä¸AIç”Ÿæˆè¿‡ç¨‹å®æ—¶åŒæ­¥")
    print("  â€¢ âœ… è¯¦ç»†æ˜¾ç¤ºæ¯ä¸ªå¤„ç†é˜¶æ®µ") 
    print("  â€¢ âœ… å½•éŸ³è‡ªåŠ¨ä¿å­˜åˆ°éŸ³é¢‘åº“")
    print("  â€¢ âœ… å†å²å½•éŸ³ç®¡ç†å’Œé‡å¤ä½¿ç”¨")
    print()
    print("ğŸ†• ä¸»è¦æ”¹è¿›:")
    print("  â€¢ ğŸ™ï¸ éŸ³é¢‘åº“ï¼šä¿å­˜ã€ç®¡ç†ã€é‡å¤ä½¿ç”¨å½•éŸ³")
    print("  â€¢ â³ è¿›åº¦åŒæ­¥ï¼šå‰å°è¿›åº¦ä¸åå°AIç”ŸæˆåŒæ­¥")
    print("  â€¢ ğŸ“Š è¯¦ç»†ç»Ÿè®¡ï¼šæ˜¾ç¤ºå®é™…ç”Ÿæˆè€—æ—¶")
    print("  â€¢ ğŸ› ï¸ æ™ºèƒ½ç®¡ç†ï¼šéŸ³é¢‘æ–‡ä»¶çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸ")
    print()
    
    print("ğŸŒ è®¿é—®åœ°å€:")
    print("  â€¢ æœ¬åœ°è®¿é—®: http://localhost:7862")
    print("  â€¢ å±€åŸŸç½‘è®¿é—®: http://0.0.0.0:7862")
    print()
    
    demo = create_final_interface()
    
    # å¯åŠ¨ç•Œé¢
    demo.launch(
        server_name="0.0.0.0",
        server_port=7862,  # ä½¿ç”¨æ–°ç«¯å£
        share=False,
        inbrowser=True,
        show_error=True
    )

if __name__ == "__main__":
    main() 