#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆæœ€ç»ˆè¯­éŸ³å…‹éš†ç½‘é¡µç•Œé¢
- æ›´æ¸…æ™°çš„é¡µé¢å¸ƒå±€
- æ›´äººæ€§åŒ–çš„æ“ä½œæµç¨‹
- ç®€åŒ–çš„åŠŸèƒ½å±•ç¤º
"""

import gradio as gr
import os
import sys
import time
import json
import datetime
import threading
import numpy as np
import librosa
import torch
import torchaudio as ta
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', 'src'))

try:
    from chatterbox import ChatterboxTTS
except ImportError:
    print("âŒ å¯¼å…¥å¤±è´¥: æ— æ³•å¯¼å…¥ChatterboxTTS")
    print("ğŸ’¡ è¯·ç¡®ä¿æ­£ç¡®å®‰è£…äº†chatterboxåŒ…")
    sys.exit(1)

# å…¨å±€å˜é‡
model = None
model_info = {}

# åˆ›å»ºè¾“å‡ºç›®å½•
output_dir = Path("output/simple_voice_cloning")
audio_library_dir = Path("output/audio_library")
temp_dir = Path("output/temp")

for dir_path in [output_dir, audio_library_dir, temp_dir]:
    dir_path.mkdir(parents=True, exist_ok=True)

# éŸ³é¢‘åº“ç´¢å¼•æ–‡ä»¶
audio_index_file = audio_library_dir / "audio_index.json"

def load_audio_index():
    """åŠ è½½éŸ³é¢‘åº“ç´¢å¼•"""
    if audio_index_file.exists():
        try:
            with open(audio_index_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_audio_index(index):
    """ä¿å­˜éŸ³é¢‘åº“ç´¢å¼•"""
    with open(audio_index_file, 'w', encoding='utf-8') as f:
        json.dump(index, f, ensure_ascii=False, indent=2)

def apply_torch_load_patch():
    """åº”ç”¨torch.loadè¡¥ä¸"""
    original_load = torch.load
    
    def patched_load(f, map_location=None, **kwargs):
        if map_location is None and not torch.cuda.is_available():
            map_location = torch.device('cpu')
        try:
            return original_load(f, map_location=map_location, **kwargs)
        except RuntimeError as e:
            if "CUDA" in str(e):
                return original_load(f, map_location=torch.device('cpu'), **kwargs)
            raise e
    
    torch.load = patched_load

def get_audio_library_list():
    """è·å–éŸ³é¢‘åº“ç®€åŒ–åˆ—è¡¨"""
    index = load_audio_index()
    if not index:
        return ["é€‰æ‹©å†å²å½•éŸ³..."]
    
    # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åˆ—ï¼Œåªæ˜¾ç¤ºæœ€è¿‘çš„10ä¸ª
    sorted_items = sorted(index.items(), key=lambda x: x[1]['created_time'], reverse=True)[:10]
    audio_list = [f"{item['name']} ({item['duration']:.1f}s)" for _, item in sorted_items]
    return ["é€‰æ‹©å†å²å½•éŸ³..."] + audio_list

def process_audio_input(audio_input, save_to_library=False, custom_name=""):
    """å¤„ç†éŸ³é¢‘è¾“å…¥ï¼ˆå½•åˆ¶/ä¸Šä¼ ï¼‰"""
    if audio_input is None:
        return None, "ğŸ™ï¸ è¯·å½•åˆ¶éŸ³é¢‘æˆ–ä¸Šä¼ æ–‡ä»¶", None
    
    try:
        # å¤„ç†éŸ³é¢‘
        if isinstance(audio_input, tuple):
            sr, audio_data = audio_input
            audio_data = audio_data.astype(np.float32)
            if len(audio_data.shape) > 1:
                audio_data = audio_data.mean(axis=1)
            duration = len(audio_data) / sr
            
            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            timestamp = int(time.time())
            temp_path = temp_dir / f"temp_audio_{timestamp}.wav"
            if np.max(np.abs(audio_data)) > 1.0:
                audio_data = audio_data / np.max(np.abs(audio_data)) * 0.95
            ta.save(temp_path, torch.from_numpy(audio_data).unsqueeze(0), sr)
            processed_path = str(temp_path)
        else:
            processed_path = audio_input
            audio_data, sr = librosa.load(audio_input, sr=None)
            duration = len(audio_data) / sr
        
        # éªŒè¯éŸ³é¢‘
        if duration < 1.0:
            return None, "âŒ éŸ³é¢‘å¤ªçŸ­ï¼Œè¯·å½•åˆ¶è‡³å°‘1ç§’çš„éŸ³é¢‘", None
        if duration > 30.0:
            return None, "âŒ éŸ³é¢‘å¤ªé•¿ï¼Œè¯·å½•åˆ¶ä¸è¶…è¿‡30ç§’çš„éŸ³é¢‘", None
        
        # ç”Ÿæˆåˆ†æä¿¡æ¯
        max_amplitude = np.max(np.abs(audio_data))
        quality = "ä¼˜ç§€" if 3 <= duration <= 10 and sr >= 16000 and max_amplitude > 0.1 else "å¯ç”¨"
        
        status_msg = f"""âœ… éŸ³é¢‘å¤„ç†æˆåŠŸï¼

ğŸ“Š éŸ³é¢‘ä¿¡æ¯:
â€¢ â±ï¸ æ—¶é•¿: {duration:.1f}ç§’  
â€¢ ğŸ“ˆ é‡‡æ ·ç‡: {sr}Hz
â€¢ ğŸµ è´¨é‡: {quality}
â€¢ ğŸ’¡ å»ºè®®: {"éŸ³é¢‘è´¨é‡å¾ˆå¥½ï¼Œé€‚åˆå…‹éš†" if quality == "ä¼˜ç§€" else "å¯ä»¥ä½¿ç”¨ï¼Œå»ºè®®å½•åˆ¶3-10ç§’é«˜è´¨é‡éŸ³é¢‘"}"""
        
        # å¦‚æœéœ€è¦ä¿å­˜åˆ°éŸ³é¢‘åº“
        if save_to_library:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            if custom_name.strip():
                safe_name = "".join(c for c in custom_name if c.isalnum() or c in (' ', '-', '_')).strip()
                filename = f"{safe_name}_{timestamp}.wav"
                display_name = safe_name
            else:
                filename = f"å½•éŸ³_{timestamp}.wav"
                display_name = f"å½•éŸ³_{timestamp}"
            
            # ä¿å­˜åˆ°éŸ³é¢‘åº“
            library_path = audio_library_dir / filename
            if isinstance(audio_input, tuple):
                ta.save(library_path, torch.from_numpy(audio_data).unsqueeze(0), sr)
            else:
                import shutil
                shutil.copy2(processed_path, library_path)
            
            # æ›´æ–°ç´¢å¼•
            index = load_audio_index()
            index[filename] = {
                "filename": filename,
                "path": str(library_path),
                "created_time": timestamp,
                "name": display_name,
                "duration": duration,
                "sample_rate": sr
            }
            save_audio_index(index)
            
            status_msg += f"\n\nğŸ’¾ å·²ä¿å­˜åˆ°éŸ³é¢‘åº“: {display_name}"
        
        return processed_path, status_msg, get_audio_library_list()
        
    except Exception as e:
        return None, f"âŒ éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}", None

def load_from_history(selected_audio):
    """ä»å†å²è®°å½•åŠ è½½éŸ³é¢‘"""
    if not selected_audio or selected_audio == "é€‰æ‹©å†å²å½•éŸ³...":
        return None, "è¯·é€‰æ‹©ä¸€ä¸ªå†å²å½•éŸ³", None
    
    try:
        index = load_audio_index()
        for filename, info in index.items():
            display_name = f"{info['name']} ({info['duration']:.1f}s)"
            if display_name == selected_audio:
                if os.path.exists(info['path']):
                    status_msg = f"""ğŸ“š å·²åŠ è½½å†å²å½•éŸ³: {info['name']}

ğŸ“Š éŸ³é¢‘ä¿¡æ¯:
â€¢ â±ï¸ æ—¶é•¿: {info['duration']:.1f}ç§’
â€¢ ğŸ“ˆ é‡‡æ ·ç‡: {info['sample_rate']}Hz  
â€¢ ğŸ“… å½•åˆ¶æ—¶é—´: {info['created_time']}

âœ… å¯ä»¥å¼€å§‹è¾“å…¥æ–‡æœ¬è¿›è¡Œè¯­éŸ³å…‹éš†ï¼"""
                    return info['path'], status_msg, None
                else:
                    return None, f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {info['path']}", None
        
        return None, "âŒ æœªæ‰¾åˆ°å¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶", None
        
    except Exception as e:
        return None, f"âŒ åŠ è½½å¤±è´¥: {str(e)}", None

def initialize_model():
    """åˆå§‹åŒ–AIæ¨¡å‹"""
    global model, model_info
    
    if model is None:
        apply_torch_load_patch()
        try:
            model = ChatterboxTTS.from_pretrained(device="cpu")
            device = "CPU (Apple Silicon)" if torch.backends.mps.is_available() else "CPU"
            model_info = {
                "name": "ChatterboxTTS",
                "device": device,
                "status": "å·²å°±ç»ª"
            }
            return f"âœ… AIæ¨¡å‹åŠ è½½æˆåŠŸï¼\nğŸ’» è¿è¡Œè®¾å¤‡: {device}\nğŸ­ çŠ¶æ€: å·²å°±ç»ª"
        except Exception as e:
            return f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}\nğŸ’¡ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œå†…å­˜ç©ºé—´"
    else:
        return f"âœ… AIæ¨¡å‹å·²å°±ç»ªï¼\nğŸ’» è®¾å¤‡: {model_info['device']}\nğŸ­ çŠ¶æ€: {model_info['status']}"

def generate_voice_clone(audio_file, text, preset_type, progress=gr.Progress()):
    """ç”Ÿæˆè¯­éŸ³å…‹éš†"""
    global model
    
    # æ£€æŸ¥æ¨¡å‹
    if model is None:
        return None, "âŒ è¯·å…ˆç­‰å¾…AIæ¨¡å‹åŠ è½½å®Œæˆï¼"
    
    # æ£€æŸ¥è¾“å…¥
    if audio_file is None:
        return None, "âŒ è¯·å…ˆå½•åˆ¶æˆ–é€‰æ‹©å‚è€ƒéŸ³é¢‘ï¼"
    
    if not text.strip():
        return None, "âŒ è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬å†…å®¹ï¼"
    
    try:
        # æ ¹æ®é¢„è®¾è®¾ç½®å‚æ•°
        preset_params = {
            "æ ‡å‡†æ¨¡å¼": {"cfg_weight": 0.8, "exaggeration": 0.6, "temperature": 0.6},
            "è‡ªç„¶è¡¨è¾¾": {"cfg_weight": 0.8, "exaggeration": 0.7, "temperature": 0.7},
            "åˆ›æ„é£æ ¼": {"cfg_weight": 0.6, "exaggeration": 1.0, "temperature": 0.9}
        }
        
        params = preset_params.get(preset_type, preset_params["æ ‡å‡†æ¨¡å¼"])
        
        # æ›´æ–°è¿›åº¦
        progress(0.1, desc="ğŸ” éªŒè¯éŸ³é¢‘...")
        time.sleep(0.5)
        
        progress(0.2, desc="ğŸ­ AIå¼€å§‹åˆ†æ...")
        time.sleep(0.8)
        
        progress(0.4, desc="ğŸ§  å­¦ä¹ å£°éŸ³ç‰¹å¾...")
        time.sleep(1.0)
        
        progress(0.6, desc="ğŸ“ å¤„ç†æ–‡æœ¬å†…å®¹...")
        time.sleep(0.8)
        
        progress(0.8, desc="ğŸµ ç”Ÿæˆè¯­éŸ³...")
        
        # ç”ŸæˆéŸ³é¢‘
        start_time = time.time()
        result_audio = model.generate(
            text=text,
            audio_prompt_path=audio_file,
            cfg_weight=params["cfg_weight"],
            exaggeration=params["exaggeration"],
            temperature=params["temperature"]
        )
        
        progress(0.95, desc="ğŸ’¾ ä¿å­˜ç»“æœ...")
        
        # ä¿å­˜ç»“æœ
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = output_dir / f"cloned_voice_{timestamp}.wav"
        ta.save(output_path, result_audio.unsqueeze(0), 24000)
        
        progress(1.0, desc="âœ… ç”Ÿæˆå®Œæˆï¼")
        
        generation_time = time.time() - start_time
        
        result_msg = f"""ğŸ‰ è¯­éŸ³å…‹éš†æˆåŠŸï¼

ğŸ“Š ç”Ÿæˆä¿¡æ¯:
â€¢ ğŸ­ ä½¿ç”¨é¢„è®¾: {preset_type}
â€¢ â±ï¸ ç”Ÿæˆè€—æ—¶: {generation_time:.1f}ç§’
â€¢ ğŸ“ æ–‡ä»¶ä½ç½®: {output_path.name}
â€¢ ğŸµ é‡‡æ ·ç‡: 24kHz

ğŸ’¡ æç¤º: å¦‚æœæ•ˆæœä¸ç†æƒ³ï¼Œå¯ä»¥å°è¯•å…¶ä»–é¢„è®¾æ¨¡å¼æˆ–é‡æ–°å½•åˆ¶æ›´æ¸…æ™°çš„å‚è€ƒéŸ³é¢‘"""
        
        return str(output_path), result_msg
        
    except Exception as e:
        return None, f"âŒ è¯­éŸ³ç”Ÿæˆå¤±è´¥: {str(e)}\nğŸ’¡ è¯·æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å’Œæ–‡æœ¬å†…å®¹"

def create_simple_interface():
    """åˆ›å»ºç®€åŒ–ç‰ˆç½‘é¡µç•Œé¢"""
    
    # ç®€æ´çš„CSSæ ·å¼
    custom_css = """
    .gradio-container {
        max-width: 1000px !important;
        margin: auto !important;
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    
    .step-card {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        border-radius: 15px;
        padding: 25px;
        margin: 15px 0;
        border: 2px solid #e0e6ed;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    
    .step-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 15px 25px;
        border-radius: 10px;
        margin-bottom: 20px;
        text-align: center;
        font-size: 18px;
        font-weight: bold;
    }
    
    .preset-btn {
        background: linear-gradient(45deg, #4CAF50, #45a049) !important;
        border: none !important;
        color: white !important;
        margin: 5px !important;
        border-radius: 8px !important;
        transition: all 0.3s ease !important;
    }
    
    .preset-btn:hover {
        transform: translateY(-2px) !important;
        box-shadow: 0 4px 12px rgba(0,0,0,0.2) !important;
    }
    
    .main-btn {
        background: linear-gradient(45deg, #FF6B6B, #FF8E53) !important;
        border: none !important;
        color: white !important;
        font-size: 18px !important;
        padding: 15px 30px !important;
        border-radius: 10px !important;
        transition: all 0.3s ease !important;
    }
    
    .main-btn:hover {
        transform: translateY(-3px) !important;
        box-shadow: 0 6px 20px rgba(0,0,0,0.3) !important;
    }
    """
    
    with gr.Blocks(css=custom_css, title="ğŸ­ ç®€åŒ–ç‰ˆè¯­éŸ³å…‹éš†", theme=gr.themes.Soft()) as demo:
        
        # æ ‡é¢˜åŒºåŸŸ
        gr.HTML("""
        <div style="text-align: center; margin: 30px 0;">
            <h1 style="color: #667eea; font-size: 36px; margin-bottom: 10px;">
                ğŸ­ æ™ºèƒ½è¯­éŸ³å…‹éš†ç³»ç»Ÿ
            </h1>
            <p style="font-size: 18px; color: #666; margin: 0;">
                ç®€å•ä¸‰æ­¥ â€¢ æ™ºèƒ½å…‹éš† â€¢ ä¸“ä¸šå“è´¨
            </p>
        </div>
        """)
        
        # æ¨¡å‹çŠ¶æ€ï¼ˆå§‹ç»ˆæ˜¾ç¤ºï¼‰
        model_status = gr.Textbox(
            label="ğŸ¤– AIæ¨¡å‹çŠ¶æ€",
            value="ğŸ”„ æ­£åœ¨åˆå§‹åŒ–AIæ¨¡å‹ï¼Œè¯·ç¨å€™...",
            interactive=False,
            lines=2
        )
        
        # æ­¥éª¤1: éŸ³é¢‘è¾“å…¥
        with gr.Group():
            gr.HTML('<div class="step-header">ğŸ™ï¸ æ­¥éª¤ 1: å½•åˆ¶æˆ–é€‰æ‹©å‚è€ƒéŸ³é¢‘</div>')
            
            with gr.Row():
                # éŸ³é¢‘å½•åˆ¶/ä¸Šä¼ 
                with gr.Column(scale=3):
                    audio_input = gr.Audio(
                        label="å½•åˆ¶æ–°éŸ³é¢‘æˆ–ä¸Šä¼ æ–‡ä»¶",
                        type="filepath",
                        sources=["upload", "microphone"],
                        show_label=True
                    )
                    
                    with gr.Row():
                        save_name = gr.Textbox(
                            label="ç»™å½•éŸ³èµ·ä¸ªåå­—ï¼ˆå¯é€‰ï¼‰",
                            placeholder="æ¯”å¦‚ï¼šæˆ‘çš„å£°éŸ³ã€å·¥ä½œå½•éŸ³...",
                            scale=2
                        )
                        save_btn = gr.Button("ğŸ’¾ ä¿å­˜", variant="secondary", scale=1)
                
                # å†å²è®°å½•é€‰æ‹©
                with gr.Column(scale=2):
                    gr.HTML("<p style='margin-bottom: 10px;'><strong>æˆ–è€…é€‰æ‹©å†å²å½•éŸ³ï¼š</strong></p>")
                    history_dropdown = gr.Dropdown(
                        choices=get_audio_library_list(),
                        label="å†å²å½•éŸ³",
                        value=None,
                        scale=1
                    )
                    load_history_btn = gr.Button("ğŸ“‚ åŠ è½½é€‰ä¸­å½•éŸ³", variant="secondary")
            
            # éŸ³é¢‘çŠ¶æ€æ˜¾ç¤º
            audio_status = gr.Textbox(
                label="ğŸ“Š éŸ³é¢‘çŠ¶æ€",
                lines=6,
                interactive=False,
                placeholder="è¯·å½•åˆ¶éŸ³é¢‘ã€ä¸Šä¼ æ–‡ä»¶æˆ–é€‰æ‹©å†å²å½•éŸ³..."
            )
        
        # æ­¥éª¤2: æ–‡æœ¬å’Œå‚æ•°
        with gr.Group():
            gr.HTML('<div class="step-header">ğŸ“ æ­¥éª¤ 2: è¾“å…¥æ–‡æœ¬å¹¶é€‰æ‹©é£æ ¼</div>')
            
            text_input = gr.Textbox(
                label="è¦åˆæˆçš„æ–‡æœ¬å†…å®¹",
                placeholder="è¯·è¾“å…¥æ‚¨å¸Œæœ›å…‹éš†è¯­éŸ³è¯´çš„å†…å®¹...\nä¾‹å¦‚ï¼šä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªè¯­éŸ³å…‹éš†æ¼”ç¤ºã€‚",
                lines=4,
                max_lines=6
            )
            
            gr.HTML("<p style='margin: 15px 0 10px 0;'><strong>ğŸ¨ é€‰æ‹©è¯­éŸ³é£æ ¼ï¼š</strong></p>")
            with gr.Row():
                preset_standard = gr.Button("ğŸ¯ æ ‡å‡†æ¨¡å¼", variant="secondary", elem_classes="preset-btn")
                preset_natural = gr.Button("ğŸ­ è‡ªç„¶è¡¨è¾¾", variant="secondary", elem_classes="preset-btn")
                preset_creative = gr.Button("ğŸ¨ åˆ›æ„é£æ ¼", variant="secondary", elem_classes="preset-btn")
            
            selected_preset = gr.Textbox(
                label="å½“å‰é€‰æ‹©",
                value="æ ‡å‡†æ¨¡å¼",
                interactive=False,
                lines=1
            )
        
        # æ­¥éª¤3: ç”Ÿæˆç»“æœ
        with gr.Group():
            gr.HTML('<div class="step-header">ğŸµ æ­¥éª¤ 3: ç”Ÿæˆè¯­éŸ³å…‹éš†</div>')
            
            generate_btn = gr.Button(
                "ğŸ­ å¼€å§‹è¯­éŸ³å…‹éš†",
                variant="primary",
                size="lg",
                elem_classes="main-btn"
            )
            
            with gr.Row():
                with gr.Column(scale=1):
                    output_audio = gr.Audio(
                        label="ğŸµ ç”Ÿæˆçš„è¯­éŸ³",
                        type="filepath",
                        interactive=False
                    )
                
                with gr.Column(scale=1):
                    result_info = gr.Textbox(
                        label="ğŸ“Š ç”Ÿæˆç»“æœ",
                        lines=8,
                        interactive=False,
                        placeholder="ç‚¹å‡»'å¼€å§‹è¯­éŸ³å…‹éš†'ç”Ÿæˆç»“æœ...",
                        show_copy_button=True
                    )
        
        # ä½¿ç”¨è¯´æ˜ï¼ˆæŠ˜å é¢æ¿ï¼‰
        with gr.Accordion("ğŸ“– ä½¿ç”¨è¯´æ˜", open=False):
            gr.HTML("""
            <div style="padding: 20px; background: #f8f9fa; border-radius: 10px; line-height: 1.6;">
                <h4>ğŸ¯ å¿«é€Ÿä¸Šæ‰‹æŒ‡å—ï¼š</h4>
                <ol style="padding-left: 20px;">
                    <li><strong>å½•åˆ¶å‚è€ƒéŸ³é¢‘</strong>ï¼šä½¿ç”¨éº¦å…‹é£å½•åˆ¶3-10ç§’æ¸…æ™°éŸ³é¢‘ï¼Œæˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶</li>
                    <li><strong>è¾“å…¥åˆæˆæ–‡æœ¬</strong>ï¼šå†™ä¸‹æ‚¨å¸Œæœ›å…‹éš†è¯­éŸ³è¯´çš„å†…å®¹</li>
                    <li><strong>é€‰æ‹©è¯­éŸ³é£æ ¼</strong>ï¼š
                        <ul style="margin: 5px 0; padding-left: 20px;">
                            <li>ğŸ¯ æ ‡å‡†æ¨¡å¼ï¼šç¨³å®šå‡†ç¡®ï¼Œé€‚åˆæ­£å¼åœºåˆ</li>
                            <li>ğŸ­ è‡ªç„¶è¡¨è¾¾ï¼šè‡ªç„¶æµç•…ï¼Œé€‚åˆæ—¥å¸¸å¯¹è¯</li>
                            <li>ğŸ¨ åˆ›æ„é£æ ¼ï¼šå¯Œæœ‰è¡¨ç°åŠ›ï¼Œé€‚åˆåˆ›æ„å†…å®¹</li>
                        </ul>
                    </li>
                    <li><strong>ç”Ÿæˆè¯­éŸ³</strong>ï¼šç‚¹å‡»æŒ‰é’®ï¼Œç­‰å¾…AIç”Ÿæˆç»“æœ</li>
                </ol>
                
                <h4>ğŸ’¡ è·å¾—æœ€ä½³æ•ˆæœçš„æŠ€å·§ï¼š</h4>
                <ul style="padding-left: 20px;">
                    <li>ğŸ™ï¸ åœ¨å®‰é™ç¯å¢ƒä¸­å½•åˆ¶ï¼Œé¿å…èƒŒæ™¯å™ªéŸ³</li>
                    <li>â±ï¸ å½•åˆ¶3-10ç§’éŸ³é¢‘ï¼Œæ—¶é•¿é€‚ä¸­æ•ˆæœæœ€å¥½</li>
                    <li>ğŸ—£ï¸ æ¸…æ™°å‘éŸ³ï¼Œè¯­é€Ÿé€‚ä¸­</li>
                    <li>ğŸ’¾ å¸¸ç”¨çš„å£°éŸ³å¯ä»¥ä¿å­˜åˆ°å†å²è®°å½•ä¸­é‡å¤ä½¿ç”¨</li>
                </ul>
                
                <h4>âš ï¸ ä½¿ç”¨æé†’ï¼š</h4>
                <p style="color: #666;">
                ä»…ç”¨äºåˆæ³•å’Œé“å¾·ç›®çš„ï¼Œè¯·å°Šé‡ä»–äººéšç§æƒç›Šã€‚AIç”Ÿæˆéœ€è¦ä¸€å®šæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚
                </p>
            </div>
            """)
        
        # äº‹ä»¶ç»‘å®š
        
        # é¡µé¢åŠ è½½æ—¶è‡ªåŠ¨åˆå§‹åŒ–æ¨¡å‹
        demo.load(
            fn=initialize_model,
            outputs=model_status
        )
        
        # éŸ³é¢‘å¤„ç†
        def process_and_update_dropdown(audio_input):
            """å¤„ç†éŸ³é¢‘å¹¶æ›´æ–°ä¸‹æ‹‰æ¡†"""
            processed_path, status_msg, updated_choices = process_audio_input(audio_input, False, "")
            return processed_path, status_msg, gr.Dropdown(choices=updated_choices, value=None)
        
        audio_input.change(
            fn=process_and_update_dropdown,
            inputs=audio_input,
            outputs=[audio_input, audio_status, history_dropdown]
        )
        
        # ä¿å­˜å½•éŸ³  
        def save_and_update_simple(audio_input, save_name):
            """ä¿å­˜å½•éŸ³å¹¶æ›´æ–°ä¸‹æ‹‰æ¡†"""
            processed_path, status_msg, updated_choices = process_audio_input(audio_input, True, save_name)
            return processed_path, status_msg, gr.Dropdown(choices=updated_choices, value=None)
        
        save_btn.click(
            fn=save_and_update_simple,
            inputs=[audio_input, save_name],
            outputs=[audio_input, audio_status, history_dropdown]
        )
        
        # åŠ è½½å†å²å½•éŸ³
        def load_and_reset_dropdown(selected_audio):
            """åŠ è½½å†å²å½•éŸ³å¹¶é‡ç½®ä¸‹æ‹‰æ¡†é€‰æ‹©"""
            audio_path, status_msg, _ = load_from_history(selected_audio)
            return audio_path, status_msg, gr.Dropdown(value=None)
        
        load_history_btn.click(
            fn=load_and_reset_dropdown,
            inputs=history_dropdown,
            outputs=[audio_input, audio_status, history_dropdown]
        )
        
        # é¢„è®¾é€‰æ‹©
        preset_standard.click(
            fn=lambda: "æ ‡å‡†æ¨¡å¼",
            outputs=selected_preset
        )
        
        preset_natural.click(
            fn=lambda: "è‡ªç„¶è¡¨è¾¾",
            outputs=selected_preset
        )
        
        preset_creative.click(
            fn=lambda: "åˆ›æ„é£æ ¼",
            outputs=selected_preset
        )
        
        # è¯­éŸ³ç”Ÿæˆ
        generate_btn.click(
            fn=generate_voice_clone,
            inputs=[audio_input, text_input, selected_preset],
            outputs=[output_audio, result_info]
        )
    
    return demo

def main():
    """å¯åŠ¨ç®€åŒ–ç‰ˆç½‘é¡µç•Œé¢"""
    print("ğŸ­ ç®€åŒ–ç‰ˆè¯­éŸ³å…‹éš†ç½‘é¡µç•Œé¢")
    print("=" * 50)
    print("ğŸŒŸ ç‰¹ç‚¹:")
    print("  â€¢ ğŸ¯ ç®€æ´æ¸…æ™°çš„ä¸‰æ­¥æµç¨‹")
    print("  â€¢ ğŸ¨ ç¾è§‚çš„å¡ç‰‡å¼å¸ƒå±€")
    print("  â€¢ ğŸš€ æ™ºèƒ½é¢„è®¾ï¼Œæ“ä½œç®€å•")
    print("  â€¢ ğŸ“± äººæ€§åŒ–çš„ç”¨æˆ·ä½“éªŒ")
    print()
    print("ğŸŒ è®¿é—®åœ°å€:")
    print("  â€¢ æœ¬åœ°è®¿é—®: http://localhost:7863")
    print("  â€¢ å±€åŸŸç½‘è®¿é—®: http://0.0.0.0:7863")
    print()
    
    demo = create_simple_interface()
    
    # å¯åŠ¨ç•Œé¢
    demo.launch(
        server_name="0.0.0.0",
        server_port=7863,
        share=False,
        inbrowser=True,
        show_error=True
    )

if __name__ == "__main__":
    main() 