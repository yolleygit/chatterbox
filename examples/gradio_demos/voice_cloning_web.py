#!/usr/bin/env python3
"""
è¯­éŸ³å…‹éš†ç½‘é¡µç•Œé¢
åŸºäºGradioå®ç°çš„å®Œæ•´è¯­éŸ³å…‹éš†æµç¨‹
åŒ…å«ï¼šå½•éŸ³ â†’ å‚æ•°è°ƒæ•´ â†’ è¯­éŸ³å…‹éš† â†’ ç»“æœè¾“å‡º
"""

import gradio as gr
import torch
import torchaudio as ta
from chatterbox.tts import ChatterboxTTS
import os
import tempfile
import time
from pathlib import Path
import numpy as np
import librosa

# å…¨å±€å˜é‡
model = None
temp_dir = Path("output/web_voice_cloning")
temp_dir.mkdir(parents=True, exist_ok=True)

def apply_torch_load_patch():
    """åº”ç”¨torch.loadè¡¥ä¸"""
    original_load = torch.load
    
    def patched_load(f, map_location=None, **kwargs):
        if map_location is None and not torch.cuda.is_available():
            map_location = torch.device('cpu')
        try:
            return original_load(f, map_location=map_location, **kwargs)
        except RuntimeError as e:
            if "CUDA" in str(e):
                return original_load(f, map_location=torch.device('cpu'), **kwargs)
            raise e
    
    torch.load = patched_load

def load_tts_model():
    """åŠ è½½TTSæ¨¡å‹"""
    global model
    if model is None:
        apply_torch_load_patch()
        try:
            model = ChatterboxTTS.from_pretrained(device="cpu")
            return "âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼"
        except Exception as e:
            return f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"
    return "âœ… æ¨¡å‹å·²å°±ç»ªï¼"

def analyze_audio(audio_file):
    """åˆ†æä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶"""
    if audio_file is None:
        return "è¯·å…ˆå½•åˆ¶æˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"
    
    try:
        # ä½¿ç”¨librosaåˆ†æéŸ³é¢‘
        if isinstance(audio_file, tuple):
            # Gradioéº¦å…‹é£å½•éŸ³æ ¼å¼ (sample_rate, audio_data)
            sr, audio_data = audio_file
            audio_data = audio_data.astype(np.float32)
            if len(audio_data.shape) > 1:
                audio_data = audio_data.mean(axis=1)  # è½¬ä¸ºå•å£°é“
            duration = len(audio_data) / sr
        else:
            # ä¸Šä¼ çš„æ–‡ä»¶
            audio_data, sr = librosa.load(audio_file, sr=None)
            duration = len(audio_data) / sr
        
        # åˆ†æç»“æœ
        max_amplitude = np.max(np.abs(audio_data))
        
        analysis = f"""
ğŸ“Š éŸ³é¢‘åˆ†æç»“æœ:
â€¢ â±ï¸ æ—¶é•¿: {duration:.2f}ç§’
â€¢ ğŸ“ˆ é‡‡æ ·ç‡: {sr}Hz
â€¢ ğŸ”Š æœ€å¤§éŸ³é‡: {max_amplitude:.3f}
â€¢ ğŸµ è´¨é‡è¯„ä¼°: {"ä¼˜ç§€" if 3 <= duration <= 10 and sr >= 16000 else "å¯ç”¨"}

ğŸ’¡ å»ºè®®:
â€¢ æœ€ä½³æ—¶é•¿: 3-10ç§’
â€¢ æ¨èé‡‡æ ·ç‡: 16kHz+
â€¢ å½•éŸ³ç¯å¢ƒ: å®‰é™æ— å™ªéŸ³
"""
        return analysis
        
    except Exception as e:
        return f"âŒ éŸ³é¢‘åˆ†æå¤±è´¥: {str(e)}"

def clone_voice(reference_audio, text, cfg_weight, exaggeration, temperature, progress=gr.Progress()):
    """æ‰§è¡Œè¯­éŸ³å…‹éš†"""
    global model
    
    if model is None:
        return None, "âŒ è¯·å…ˆåŠ è½½æ¨¡å‹ï¼"
    
    if reference_audio is None:
        return None, "âŒ è¯·å…ˆå½•åˆ¶æˆ–ä¸Šä¼ å‚è€ƒéŸ³é¢‘ï¼"
    
    if not text.strip():
        return None, "âŒ è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬ï¼"
    
    try:
        progress(0.1, desc="å‡†å¤‡éŸ³é¢‘æ–‡ä»¶...")
        
        # å¤„ç†å‚è€ƒéŸ³é¢‘
        reference_path = None
        if isinstance(reference_audio, tuple):
            # éº¦å…‹é£å½•éŸ³
            sr, audio_data = reference_audio
            audio_data = audio_data.astype(np.float32)
            if len(audio_data.shape) > 1:
                audio_data = audio_data.mean(axis=1)
            
            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            reference_path = temp_dir / f"reference_{int(time.time())}.wav"
            ta.save(reference_path, torch.from_numpy(audio_data).unsqueeze(0), sr)
        else:
            # ä¸Šä¼ çš„æ–‡ä»¶
            reference_path = reference_audio
        
        progress(0.3, desc="å¼€å§‹è¯­éŸ³å…‹éš†...")
        
        # è¯­éŸ³å…‹éš†
        wav_tensor = model.generate(
            text=text,
            audio_prompt_path=str(reference_path),
            cfg_weight=cfg_weight,
            exaggeration=exaggeration,
            temperature=temperature
        )
        
        progress(0.8, desc="ä¿å­˜ç»“æœ...")
        
        # ä¿å­˜ç»“æœ
        timestamp = int(time.time())
        output_path = temp_dir / f"cloned_voice_{timestamp}.wav"
        ta.save(output_path, wav_tensor, model.sr)
        
        # è®¡ç®—éŸ³é¢‘ä¿¡æ¯
        audio_duration = wav_tensor.shape[1] / model.sr
        
        progress(1.0, desc="å®Œæˆï¼")
        
        result_info = f"""
ğŸ‰ è¯­éŸ³å…‹éš†å®Œæˆï¼

ğŸ“Š ç”Ÿæˆä¿¡æ¯:
â€¢ ğŸ¼ éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f}ç§’
â€¢ ğŸ“ ä¿å­˜è·¯å¾„: {output_path}
â€¢ âš™ï¸ ä½¿ç”¨å‚æ•°:
  - cfg_weight: {cfg_weight}
  - exaggeration: {exaggeration}
  - temperature: {temperature}

ğŸ’¡ æç¤º: å¯ä»¥è°ƒæ•´å‚æ•°é‡æ–°ç”Ÿæˆä»¥è·å¾—ä¸åŒæ•ˆæœ
"""
        
        return str(output_path), result_info
        
    except Exception as e:
        return None, f"âŒ è¯­éŸ³å…‹éš†å¤±è´¥: {str(e)}"

def get_parameter_tips(cfg_weight, exaggeration, temperature):
    """è·å–å‚æ•°è°ƒä¼˜æç¤º"""
    tips = f"""
ğŸ›ï¸ å½“å‰å‚æ•°è®¾ç½®:

ğŸ“Š cfg_weight = {cfg_weight}
{'ğŸ”´ ä½ç›¸ä¼¼åº¦ - æ›´æœ‰åˆ›æ„' if cfg_weight < 0.6 else 'ğŸŸ¡ ä¸­ç­‰ç›¸ä¼¼åº¦ - å¹³è¡¡' if cfg_weight < 0.8 else 'ğŸŸ¢ é«˜ç›¸ä¼¼åº¦ - æ›´åƒåŸå£°'}

ğŸ­ exaggeration = {exaggeration}
{'ğŸ”µ ä½è¡¨è¾¾ - å¹³æ·¡é£æ ¼' if exaggeration < 0.6 else 'ğŸŸ¡ ä¸­ç­‰è¡¨è¾¾ - è‡ªç„¶é£æ ¼' if exaggeration < 1.0 else 'ğŸŸ  é«˜è¡¨è¾¾ - å¤¸å¼ é£æ ¼'}

ğŸ² temperature = {temperature}
{'ğŸŸ¢ ä½éšæœºæ€§ - ç¨³å®šä¸€è‡´' if temperature < 0.7 else 'ğŸŸ¡ ä¸­ç­‰éšæœºæ€§ - å¹³è¡¡' if temperature < 1.0 else 'ğŸ”´ é«˜éšæœºæ€§ - å¤šæ ·å˜åŒ–'}

ğŸ’¡ ä¼˜åŒ–å»ºè®®:
â€¢ æƒ³è¦æ›´åƒåŸå£° â†’ æé«˜ cfg_weight
â€¢ æƒ³è¦æ›´æœ‰è¡¨ç°åŠ› â†’ æé«˜ exaggeration
â€¢ æƒ³è¦æ›´ç¨³å®š â†’ é™ä½ temperature
â€¢ æƒ³è¦æ›´å¤šå˜åŒ– â†’ æé«˜ temperature
"""
    return tips

def create_web_interface():
    """åˆ›å»ºç½‘é¡µç•Œé¢"""
    
    # è‡ªå®šä¹‰CSSæ ·å¼
    css = """
    .gradio-container {
        max-width: 1200px !important;
        margin: auto !important;
    }
    .tab-nav {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%) !important;
    }
    .gr-button {
        background: linear-gradient(45deg, #667eea, #764ba2) !important;
        border: none !important;
        color: white !important;
    }
    .gr-button:hover {
        transform: translateY(-2px) !important;
        box-shadow: 0 5px 15px rgba(0,0,0,0.2) !important;
    }
    """
    
    with gr.Blocks(css=css, title="ğŸ­ è¯­éŸ³å…‹éš†å·¥å…·", theme=gr.themes.Soft()) as interface:
        
        gr.HTML("""
        <div style="text-align: center; margin: 20px;">
            <h1>ğŸ­ æ™ºèƒ½è¯­éŸ³å…‹éš†ç³»ç»Ÿ</h1>
            <p style="font-size: 18px; color: #666;">
                é€šè¿‡AIæŠ€æœ¯å®ç°ä¸ªæ€§åŒ–è¯­éŸ³å…‹éš†ï¼Œç®€å•æ˜“ç”¨ï¼Œæ•ˆæœå‡ºè‰²
            </p>
        </div>
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.HTML("<h2>ğŸ™ï¸ æ­¥éª¤1: å‡†å¤‡å‚è€ƒéŸ³é¢‘</h2>")
                
                with gr.Tab("ğŸ“± éº¦å…‹é£å½•éŸ³"):
                    microphone_input = gr.Audio(
                        sources=["microphone"],
                        type="numpy",
                        label="ç‚¹å‡»å½•åˆ¶æ‚¨çš„å£°éŸ³ (3-10ç§’)",
                        show_label=True
                    )
                    
                with gr.Tab("ğŸ“ ä¸Šä¼ æ–‡ä»¶"):
                    file_input = gr.Audio(
                        sources=["upload"],
                        type="filepath",
                        label="ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ (WAV/MP3/FLAC)",
                        show_label=True
                    )
                
                analyze_btn = gr.Button("ğŸ” åˆ†æéŸ³é¢‘è´¨é‡", variant="secondary")
                audio_analysis = gr.Textbox(
                    label="éŸ³é¢‘åˆ†æç»“æœ",
                    lines=8,
                    interactive=False,
                    placeholder="ç‚¹å‡»'åˆ†æéŸ³é¢‘è´¨é‡'æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯..."
                )
        
            with gr.Column(scale=1):
                gr.HTML("<h2>âš™ï¸ æ­¥éª¤2: è°ƒæ•´å‚æ•°</h2>")
                
                cfg_weight = gr.Slider(
                    minimum=0.1,
                    maximum=1.0,
                    value=0.8,
                    step=0.1,
                    label="ğŸ¯ ç›¸ä¼¼åº¦æ§åˆ¶ (cfg_weight)",
                    info="è¶Šé«˜è¶Šåƒå‚è€ƒéŸ³é¢‘"
                )
                
                exaggeration = gr.Slider(
                    minimum=0.1,
                    maximum=2.0,
                    value=0.7,
                    step=0.1,
                    label="ğŸ­ æƒ…æ„Ÿè¡¨è¾¾åº¦ (exaggeration)",
                    info="æ§åˆ¶è¯­éŸ³çš„è¡¨ç°åŠ›"
                )
                
                temperature = gr.Slider(
                    minimum=0.1,
                    maximum=2.0,
                    value=0.7,
                    step=0.1,
                    label="ğŸ² éšæœºæ€§æ§åˆ¶ (temperature)",
                    info="æ§åˆ¶ç”Ÿæˆçš„å¤šæ ·æ€§"
                )
                
                parameter_tips = gr.Textbox(
                    label="å‚æ•°è°ƒä¼˜æç¤º",
                    lines=8,
                    interactive=False,
                    value=get_parameter_tips(0.8, 0.7, 0.7)
                )
        
        gr.HTML("<hr>")
        
        with gr.Row():
            with gr.Column(scale=2):
                gr.HTML("<h2>ğŸ“ æ­¥éª¤3: è¾“å…¥æ–‡æœ¬</h2>")
                text_input = gr.Textbox(
                    label="è¦åˆæˆçš„æ–‡æœ¬å†…å®¹",
                    placeholder="è¯·è¾“å…¥æ‚¨æƒ³è¦å…‹éš†è¯­éŸ³è¯´çš„å†…å®¹...",
                    lines=3,
                    max_lines=5
                )
                
                with gr.Row():
                    load_model_btn = gr.Button("ğŸš€ åŠ è½½æ¨¡å‹", variant="secondary")
                    clone_btn = gr.Button("ğŸ­ å¼€å§‹è¯­éŸ³å…‹éš†", variant="primary", size="lg")
                
                model_status = gr.Textbox(
                    label="æ¨¡å‹çŠ¶æ€",
                    value="ç‚¹å‡»'åŠ è½½æ¨¡å‹'å¼€å§‹",
                    interactive=False
                )
            
            with gr.Column(scale=1):
                gr.HTML("<h2>ğŸµ æ­¥éª¤4: å…‹éš†ç»“æœ</h2>")
                
                output_audio = gr.Audio(
                    label="å…‹éš†çš„è¯­éŸ³",
                    type="filepath",
                    interactive=False
                )
                
                result_info = gr.Textbox(
                    label="ç”Ÿæˆç»“æœä¿¡æ¯",
                    lines=8,
                    interactive=False,
                    placeholder="ç‚¹å‡»'å¼€å§‹è¯­éŸ³å…‹éš†'ç”Ÿæˆç»“æœ..."
                )
        
        # é¢„è®¾ç¤ºä¾‹
        gr.HTML("<hr>")
        gr.HTML("<h2>ğŸ’¡ å¿«é€Ÿå¼€å§‹ç¤ºä¾‹</h2>")
        
        with gr.Row():
            gr.Examples(
                examples=[
                    ["Hello, this is a voice cloning demonstration.", 0.8, 0.7, 0.7],
                    ["Good morning! How are you doing today?", 0.9, 0.5, 0.6],
                    ["Welcome to our amazing voice cloning service!", 0.7, 1.0, 0.8],
                    ["Thank you for trying out this technology.", 0.8, 0.6, 0.5]
                ],
                inputs=[text_input, cfg_weight, exaggeration, temperature],
                label="ç‚¹å‡»ç¤ºä¾‹å¿«é€Ÿå¡«å…¥å‚æ•°"
            )
        
        # ä½¿ç”¨è¯´æ˜
        with gr.Accordion("ğŸ“– ä½¿ç”¨è¯´æ˜", open=False):
            gr.HTML("""
            <div style="padding: 20px; background: #f8f9fa; border-radius: 10px;">
                <h3>ğŸ¯ ä½¿ç”¨æ­¥éª¤:</h3>
                <ol>
                    <li><strong>å½•åˆ¶/ä¸Šä¼ éŸ³é¢‘</strong>: ä½¿ç”¨éº¦å…‹é£å½•åˆ¶3-10ç§’æ¸…æ™°è¯­éŸ³ï¼Œæˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶</li>
                    <li><strong>åˆ†æéŸ³é¢‘</strong>: ç‚¹å‡»"åˆ†æéŸ³é¢‘è´¨é‡"æ£€æŸ¥éŸ³é¢‘æ˜¯å¦ç¬¦åˆè¦æ±‚</li>
                    <li><strong>è°ƒæ•´å‚æ•°</strong>: æ ¹æ®éœ€è¦è°ƒæ•´ç›¸ä¼¼åº¦ã€è¡¨è¾¾åº¦å’Œéšæœºæ€§å‚æ•°</li>
                    <li><strong>åŠ è½½æ¨¡å‹</strong>: ç‚¹å‡»"åŠ è½½æ¨¡å‹"åˆå§‹åŒ–AIæ¨¡å‹</li>
                    <li><strong>è¾“å…¥æ–‡æœ¬</strong>: è¾“å…¥æ‚¨æƒ³è¦å…‹éš†è¯­éŸ³è¯´çš„å†…å®¹</li>
                    <li><strong>å¼€å§‹å…‹éš†</strong>: ç‚¹å‡»"å¼€å§‹è¯­éŸ³å…‹éš†"ç”Ÿæˆç»“æœ</li>
                </ol>
                
                <h3>ğŸ›ï¸ å‚æ•°è¯´æ˜:</h3>
                <ul>
                    <li><strong>ç›¸ä¼¼åº¦æ§åˆ¶</strong>: 0.8-0.9é€‚åˆé«˜è´¨é‡å…‹éš†ï¼Œ0.5-0.7é€‚åˆåˆ›æ„è¡¨è¾¾</li>
                    <li><strong>æƒ…æ„Ÿè¡¨è¾¾åº¦</strong>: 0.4-0.6é€‚åˆæ­£å¼åœºåˆï¼Œ0.7-1.2é€‚åˆç”ŸåŠ¨è¡¨è¾¾</li>
                    <li><strong>éšæœºæ€§æ§åˆ¶</strong>: 0.5-0.7é€‚åˆç¨³å®šè¾“å‡ºï¼Œ0.8-1.2é€‚åˆå¤šæ ·å˜åŒ–</li>
                </ul>
                
                <h3>âš ï¸ æ³¨æ„äº‹é¡¹:</h3>
                <ul>
                    <li>ä»…ç”¨äºåˆæ³•å’Œé“å¾·ç›®çš„</li>
                    <li>ä½¿ç”¨ä»–äººå£°éŸ³éœ€è·å¾—åŒæ„</li>
                    <li>ä¸å¾—ç”¨äºæ¬ºè¯ˆæˆ–è¯¯å¯¼</li>
                    <li>é¦–æ¬¡åŠ è½½æ¨¡å‹éœ€è¦è¾ƒé•¿æ—¶é—´</li>
                </ul>
            </div>
            """)
        
        # äº‹ä»¶ç»‘å®š
        load_model_btn.click(
            fn=load_tts_model,
            outputs=model_status
        )
        
        analyze_btn.click(
            fn=analyze_audio,
            inputs=[microphone_input],  # ä¼˜å…ˆä½¿ç”¨éº¦å…‹é£è¾“å…¥
            outputs=audio_analysis
        )
        
        # å½“å‚æ•°å˜åŒ–æ—¶æ›´æ–°æç¤º
        for param in [cfg_weight, exaggeration, temperature]:
            param.change(
                fn=get_parameter_tips,
                inputs=[cfg_weight, exaggeration, temperature],
                outputs=parameter_tips
            )
        
        clone_btn.click(
            fn=clone_voice,
            inputs=[
                microphone_input,  # ä½¿ç”¨éº¦å…‹é£è¾“å…¥ä½œä¸ºä¸»è¦å‚è€ƒ
                text_input,
                cfg_weight,
                exaggeration,
                temperature
            ],
            outputs=[output_audio, result_info]
        )
        
        # å¦‚æœéº¦å…‹é£æ²¡æœ‰è¾“å…¥ï¼Œå°è¯•ä½¿ç”¨æ–‡ä»¶è¾“å…¥
        def use_file_input_if_needed(mic_input, file_input, text, cfg, exag, temp):
            reference = mic_input if mic_input is not None else file_input
            return clone_voice(reference, text, cfg, exag, temp)
        
        # æ·»åŠ å¤‡ç”¨å…‹éš†æŒ‰é’®é€»è¾‘
        clone_btn.click(
            fn=use_file_input_if_needed,
            inputs=[microphone_input, file_input, text_input, cfg_weight, exaggeration, temperature],
            outputs=[output_audio, result_info]
        )
    
    return interface

def main():
    """å¯åŠ¨ç½‘é¡µåº”ç”¨"""
    print("ğŸš€ å¯åŠ¨è¯­éŸ³å…‹éš†ç½‘é¡µç•Œé¢...")
    
    interface = create_web_interface()
    
    # å¯åŠ¨ç•Œé¢
    interface.launch(
        server_name="0.0.0.0",  # å…è®¸å¤–éƒ¨è®¿é—®
        server_port=7860,        # ç«¯å£å·
        share=False,             # ä¸åˆ›å»ºå…¬å…±é“¾æ¥
        debug=True,              # è°ƒè¯•æ¨¡å¼
        show_error=True,         # æ˜¾ç¤ºé”™è¯¯
        inbrowser=True           # è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
    )

if __name__ == "__main__":
    main() 