#!/usr/bin/env python3
"""
Macè®¾å¤‡æ˜ å°„è¡¥ä¸
è§£å†³åœ¨Macç³»ç»Ÿä¸Šè¿è¡ŒChatterbox TTSæ—¶çš„CUDAè®¾å¤‡æ˜ å°„é—®é¢˜
"""

import torch
import os
from pathlib import Path

def patch_torch_load():
    """
    ä¸ºMacç³»ç»Ÿä¿®è¡¥torch.loadå‡½æ•°ï¼Œè‡ªåŠ¨å¤„ç†è®¾å¤‡æ˜ å°„
    """
    original_load = torch.load
    
    def patched_load(f, map_location=None, **kwargs):
        """ä¿®è¡¥çš„torch.loadå‡½æ•°ï¼Œè‡ªåŠ¨å¤„ç†è®¾å¤‡æ˜ å°„"""
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šmap_locationä¸”åœ¨Macä¸Šï¼Œè‡ªåŠ¨æ˜ å°„åˆ°CPU
        if map_location is None:
            if torch.backends.mps.is_available():
                # Apple Silicon Mac - å…ˆåŠ è½½åˆ°CPU
                map_location = torch.device('cpu')
            elif not torch.cuda.is_available():
                # å…¶ä»–Macç³»ç»Ÿ - æ˜ å°„åˆ°CPU
                map_location = torch.device('cpu')
        
        try:
            return original_load(f, map_location=map_location, **kwargs)
        except RuntimeError as e:
            if "CUDA" in str(e) and "torch.cuda.is_available() is False" in str(e):
                print(f"âš ï¸  è‡ªåŠ¨ä¿®å¤CUDAè®¾å¤‡æ˜ å°„é—®é¢˜: {f}")
                return original_load(f, map_location=torch.device('cpu'), **kwargs)
            else:
                raise e
    
    # æ›¿æ¢torch.load
    torch.load = patched_load
    print("ğŸ”§ Macè®¾å¤‡æ˜ å°„è¡¥ä¸å·²åº”ç”¨")

def apply_mac_optimizations():
    """
    åº”ç”¨Macç³»ç»Ÿçš„å„ç§ä¼˜åŒ–è®¾ç½®
    """
    # åº”ç”¨torch.loadè¡¥ä¸
    patch_torch_load()
    
    # è®¾ç½®ç¯å¢ƒå˜é‡ä¼˜åŒ–
    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'  # å¯ç”¨MPSå›é€€
    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'  # å†…å­˜ç®¡ç†ä¼˜åŒ–
    
    # è®¾ç½®å¤šçº¿ç¨‹ä¼˜åŒ–
    if torch.get_num_threads() > 4:
        torch.set_num_threads(4)  # é™åˆ¶çº¿ç¨‹æ•°ï¼Œé¿å…è¿‡åº¦å ç”¨
    
    print("ğŸ Macç³»ç»Ÿä¼˜åŒ–è®¾ç½®å·²åº”ç”¨")

def get_optimal_device():
    """
    è·å–Macç³»ç»Ÿçš„æœ€ä½³è®¡ç®—è®¾å¤‡
    
    Returns:
        str: æœ€ä½³è®¾å¤‡åç§° ('mps', 'cpu')
    """
    if torch.backends.mps.is_available():
        # æ£€æŸ¥MPSæ˜¯å¦çœŸæ­£å¯ç”¨
        try:
            test_tensor = torch.tensor([1.0], device='mps')
            _ = test_tensor + 1
            return 'mps'
        except:
            print("âš ï¸  MPSè®¾å¤‡æ£€æµ‹å¤±è´¥ï¼Œå›é€€åˆ°CPU")
            return 'cpu'
    else:
        return 'cpu'

def verify_mac_setup():
    """
    éªŒè¯Macç³»ç»Ÿè®¾ç½®
    """
    print("ğŸ” éªŒè¯Macç³»ç»Ÿè®¾ç½®...")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"MPSå¯ç”¨: {torch.backends.mps.is_available()}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    device = get_optimal_device()
    print(f"æ¨èè®¾å¤‡: {device}")
    
    if device == 'mps':
        print("ğŸš€ æ‚¨çš„Macæ”¯æŒMetal Performance ShadersåŠ é€Ÿ")
    else:
        print("ğŸ’» å°†ä½¿ç”¨CPUè¿›è¡Œæ¨ç†")
    
    return device

if __name__ == "__main__":
    # åº”ç”¨Macä¼˜åŒ–
    apply_mac_optimizations()
    
    # éªŒè¯è®¾ç½®
    device = verify_mac_setup()
    
    print("\nğŸ“‹ ä½¿ç”¨å»ºè®®:")
    print("1. åœ¨å¯¼å…¥chatterboxä¹‹å‰è¿è¡Œæ­¤è¡¥ä¸")
    print("2. ä½¿ç”¨è¿”å›çš„deviceå‚æ•°åˆå§‹åŒ–æ¨¡å‹") 
    print("3. å¦‚é‡åˆ°å†…å­˜é—®é¢˜ï¼Œé‡å¯Pythonä¼šè¯") 